"""
RAG STRESS TEST v2: Mirror Traps (–ó–µ—Ä–∫–∞–ª—å–Ω—ã–µ –õ–æ–≤—É—à–∫–∏)
======================================================
Testing semantic search resilience against:
- Similar names (–ö—Ä–æ—Å—Å vs –ì—Ä–æ—Å—Å, –•–∏–º–µ—Ä–∞ vs –ì–∏–¥—Ä–∞)
- Similar numbers (45.5 vs 4.55, $1.5M vs $150)
- In-text corrections (v4.1 was decoy, v4.0 is real)
- Cross-references and redirections

Goal: 6/6 = CIA-level analyst ready
"""
import asyncio
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# HARDCORE TRAP QUESTIONS
TEST_CASES = [
    {
        "id": 1,
        "trap": "Time & Port Trap",
        "question": "–í–æ —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ç–æ—Ä–∂–µ–Ω–∏–µ –∏ —á–µ—Ä–µ–∑ –∫–∞–∫–æ–π –ø–æ—Ä—Ç?",
        "expected": "04:15, –ø–æ—Ä—Ç 8008",
        "keywords": ["04:15", "8008"],
        "anti_keywords": ["04:00", "8080"],  # WRONG answers
        "explanation": "Text says 04:00/8080 was FALSE alarm, real was 04:15/8008"
    },
    {
        "id": 2,
        "trap": "Version Decoy Trap", 
        "question": "–ö–∞–∫–∞—è –≤–µ—Ä—Å–∏—è —ç–∫—Å–ø–ª–æ–π—Ç–∞ Red-Snake –Ω–∞–Ω–µ—Å–ª–∞ —Ä–µ–∞–ª—å–Ω—ã–π —É—â–µ—Ä–±?",
        "expected": "v4.0",
        "keywords": ["4.0", "v4.0"],
        "anti_keywords": ["4.1", "v4.1"],
        "explanation": "v4.1 was decoy/cover, v4.0 was real"
    },
    {
        "id": 3,
        "trap": "Similar Names Trap",
        "question": "–ß–µ—Ä—Ç–µ–∂–∏ –∫–∞–∫–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –±—ã–ª–∏ –≤ –∏—Ç–æ–≥–µ —É–∫—Ä–∞–¥–µ–Ω—ã?",
        "expected": "–ì–∏–¥—Ä–∞ / Hydra (–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –±–æ—Ç)",
        "keywords": ["–≥–∏–¥—Ä–∞", "hydra", "–º–µ–¥–∏—Ü–∏–Ω"],
        "anti_keywords": ["—Ö–∏–º–µ—Ä–∞", "chimera", "–±–æ–µ–≤"],
        "explanation": "Attacker TRIED to steal Chimera but got Hydra due to script error"
    },
    {
        "id": 4,
        "trap": "Weight Confusion Trap",
        "question": "–°–∫–æ–ª—å–∫–æ –≤–µ—Å–∏—Ç —É–∫—Ä–∞–¥–µ–Ω–Ω—ã–π —Ä–æ–±–æ—Ç?",
        "expected": "4.55 –∫–≥",
        "keywords": ["4.55", "4,55"],
        "anti_keywords": ["45.5", "45,5"],
        "explanation": "Hydra is 4.55 kg, Chimera is 45.5 kg - must not confuse"
    },
    {
        "id": 5,
        "trap": "Name/ID Confusion Trap",
        "question": "–ö–∞–∫–æ–π ID —É –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞—à–ª–∏ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏—Å–∫?",
        "expected": "77-43-A (–í–∏–∫—Ç–æ—Ä –ì—Ä–æ—Å—Å)",
        "keywords": ["77-43-a", "–≥—Ä–æ—Å—Å"],
        "anti_keywords": ["77-34-a", "–∫—Ä–æ—Å—Å"],
        "explanation": "Disk found at –ì—Ä–æ—Å—Å (77-43-A), not –ö—Ä–æ—Å—Å (77-34-A with alibi)"
    },
    {
        "id": 6,
        "trap": "Financial Revaluation Trap",
        "question": "–ö–∞–∫–æ–π —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π —É—â–µ—Ä–± –ø–æ–Ω–µ—Å–ª–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ –∞—É–¥–∏—Ç–∞?",
        "expected": "$150.00 / —Å—Ç–æ –ø—è—Ç—å–¥–µ—Å—è—Ç –¥–æ–ª–ª–∞—Ä–æ–≤",
        "keywords": ["150", "—Å—Ç–æ –ø—è—Ç—å–¥–µ—Å—è—Ç"],
        "anti_keywords": ["1,500,000", "1.5", "–ø–æ–ª—Ç–æ—Ä–∞ –º–∏–ª–ª–∏–æ–Ω"],
        "explanation": "Initial was $1.5M, but after audit reassessed to $150 (legacy schemas)"
    }
]


def check_answer(answer: str, test_case: dict) -> tuple[bool, str, list[str]]:
    """Check answer with trap detection."""
    answer_lower = answer.lower()
    
    # Check for WRONG (trap) keywords first
    traps_triggered = []
    for anti in test_case.get("anti_keywords", []):
        if anti.lower() in answer_lower:
            traps_triggered.append(anti)
    
    # Check for correct keywords
    found = [kw for kw in test_case["keywords"] if kw.lower() in answer_lower]
    
    if found and not traps_triggered:
        return True, f"Found: {', '.join(found)}", []
    elif traps_triggered:
        return False, f"TRAP TRIGGERED! Wrong values mentioned", traps_triggered
    else:
        return False, "Expected keywords not found", []


async def main():
    print("=" * 70)
    print("RAG STRESS TEST v2: MIRROR TRAPS (–ó–µ—Ä–∫–∞–ª—å–Ω—ã–µ –õ–æ–≤—É—à–∫–∏)")
    print("=" * 70)
    print("Testing: Similar names, decoy values, in-text corrections\n")
    
    # Init
    from src.core.config import config
    from src.core.lm_client import lm_client
    from src.core.rag import rag
    from src.core.memory import memory
    
    await memory.initialize()
    await rag.initialize(memory._db)
    
    print(f"[INIT] Database: {memory.db_path}")
    print(f"[INIT] Embedding: {config.memory.embedding_model}")
    
    # Remove old test document and reindex
    print("\n[LOAD] Clearing old index and reindexing...")
    existing_docs = await rag.list_documents()
    for doc in existing_docs:
        if "–¢–ï–°–¢" in doc.filename:
            await rag.remove_document(doc.id)
            print(f"  Removed old: {doc.filename}")
    
    # Index new document
    test_doc_path = os.path.join(os.path.dirname(__file__), "–¢–ï–°–¢.txt")
    doc = await rag.add_document(test_doc_path)
    print(f"  Indexed: {doc.filename} -> {doc.chunk_count} chunks")
    
    # Run tests
    print("\n[TEST] Running 6 TRAP questions...")
    print("-" * 70)
    
    results = {"passed": 0, "failed": 0, "trapped": 0}
    
    for tc in TEST_CASES:
        print(f"\n[Q{tc['id']}] ü™§ {tc['trap']}")
        print(f"    Q: {tc['question']}")
        
        # Get RAG context
        context = await rag.get_context_for_query(tc["question"], max_tokens=3000)
        
        if not context:
            print(f"    ‚ö†Ô∏è No context found!")
            results["failed"] += 1
            continue
        
        # Build prompt
        prompt = f"""–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
–í–ê–ñ–ù–û: –í —Ç–µ–∫—Å—Ç–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–ø—Ä–æ–≤–µ—Ä–∂–µ–Ω–∏—è –∏ —É—Ç–æ—á–Ω–µ–Ω–∏—è. –ß–∏—Ç–∞–π –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –¥–æ –∫–æ–Ω—Ü–∞ –∞–±–∑–∞—Ü–∞.

{context}

–í–æ–ø—Ä–æ—Å: {tc["question"]}

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ. –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ü–∏—Ñ—Ä—ã, –∏–º–µ–Ω–∞, –≤–µ—Ä—Å–∏–∏)."""

        try:
            response = ""
            async for chunk in await lm_client.chat(
                messages=[{"role": "user", "content": prompt}],
                model="mistralai-mistral-nemo-instruct-2407-12b-mpoa-v1-i1",
                stream=True,
                temperature=0.05,  # Very low for precision
                max_tokens=150
            ):
                response += chunk
            
            print(f"    A: {response.strip()[:150]}...")
            
            passed, reason, traps = check_answer(response, tc)
            
            if passed:
                print(f"    ‚úÖ PASS ({reason})")
                results["passed"] += 1
            elif traps:
                print(f"    ‚ùå TRAPPED! Fell for: {traps}")
                print(f"       Expected: {tc['expected']}")
                print(f"       Why: {tc['explanation']}")
                results["trapped"] += 1
                results["failed"] += 1
            else:
                print(f"    ‚ùå FAIL - {reason}")
                print(f"       Expected: {tc['expected']}")
                results["failed"] += 1
                
        except Exception as e:
            print(f"    ERROR: {e}")
            results["failed"] += 1
    
    # Summary
    print("\n" + "=" * 70)
    print("RESULTS SUMMARY")
    print("=" * 70)
    print(f"  ‚úÖ Passed:  {results['passed']}/6")
    print(f"  ‚ùå Failed:  {results['failed']}/6")
    print(f"  ü™§ Trapped: {results['trapped']}/6 (fell for decoys)")
    
    if results["passed"] == 6:
        print("\nüèÜ CIA-LEVEL ANALYST READY! Perfect semantic understanding!")
    elif results["passed"] >= 4:
        print("\n‚ö†Ô∏è GOOD but not perfect. Some traps caught the model.")
    else:
        print("\n‚ùå NEEDS IMPROVEMENT. Semantic search failed trap detection.")
    
    return results


if __name__ == "__main__":
    asyncio.run(main())
