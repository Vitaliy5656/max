# üöÄ Optimization Report: SmartRouter Features Plan

> **–î–∞—Ç–∞:** 2025-12-14 02:10
> **–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø–ª–∞–Ω:** `MIND/router_features_plan.md`
> **–°—Ç–∞—Ç—É—Å:** ‚ö†Ô∏è –ù—É–∂–Ω—ã trade-offs

---

## üìä Performance Impact Analysis

### Performance Budgets –¥–ª—è SmartRouter

| –û–ø–µ—Ä–∞—Ü–∏—è | –ë—é–¥–∂–µ—Ç | Risk |
|----------|--------|------|
| Routing Decision | < 50ms | üü¢ LOW |
| LLM Classification (Phi-3.5) | < 500ms | üü° MEDIUM |
| Full SmartRouter (–≤—Å–µ —Ñ–∏—á–∏) | < 200ms | üî¥ HIGH |

---

## üöÄ INSTANT WIN (5 —Ñ–∏—á–µ–π)

### 1. Temperature Auto-Tune

**Impact:** ZERO latency

```python
# –ü—Ä–æ—Å—Ç–æ lookup table, O(1)
TEMP_MAP = {"coding": 0.3, "creative": 0.9, "math": 0.1}
temperature = TEMP_MAP.get(intent, 0.7)
```

‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å inline –≤ SmartRouter

### 2. Auto Mode Selection

**Impact:** ZERO latency (—É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–æ –≤ LLM Router)

```python
mode = routing_decision.suggested_mode  # already computed
```

‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∏–∑ LLMRouter

### 3. RAG Trigger

**Impact:** NEGATIVE latency (—ç–∫–æ–Ω–æ–º–∏–º –∫–æ–≥–¥–∞ skip)

```python
# Skip RAG = —ç–∫–æ–Ω–æ–º–∏—è 100-500ms
skip_rag = intent in [GREETING, SIMPLE_MATH]
```

‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** Whitelist –¥–ª—è skip –≤–º–µ—Å—Ç–æ blacklist

### 4. Context Window Optimizer

**Impact:** NEGATIVE latency (–º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –±—ã—Å—Ç—Ä–µ–µ)

```python
context_sizes = {"simple": 2, "medium": 10, "complex": 50}
```

‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –¥–ª—è simple

### 5. Cost Estimator

**Impact:** ZERO latency

```python
# –ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞
tokens = complexity_factor * avg_response_length
time_ms = tokens * ms_per_token
```

‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–∞–∫ lookup + multiply

---

## ‚öñÔ∏è TRADE-OFF (5 —Ñ–∏—á–µ–π)

### 6. LLM Router (Phi-3.5) - –£–ñ–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù

**Current latency:** ~500ms per call
**Trade-off:** +500ms latency vs accurate classification

‚öñÔ∏è **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# 1. Cache –ø–æ message prefix (—ç–∫–æ–Ω–æ–º–∏—è 90% –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö)
cache_key = message[:50].lower()

# 2. Timeout fallback –Ω–∞ CPU Router
try:
    result = await asyncio.wait_for(llm_router.route(msg), timeout=0.5)
except asyncio.TimeoutError:
    result = cpu_router.route(msg)  # Fallback: 0ms
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚úÖ –î–æ–±–∞–≤–∏—Ç—å cache + timeout fallback

### 7. Privacy Lock System

**Impact:** ~5ms (string match)
**Trade-off:** Security > Speed

‚öñÔ∏è **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# Compiled regex –≤–º–µ—Å—Ç–æ string.contains
UNLOCK_PATTERN = re.compile(r"–ø—Ä–∏–≤–µ—Ç,?\s+–º–∞–ª—ã—à", re.IGNORECASE)
is_unlock = UNLOCK_PATTERN.search(message) is not None
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚úÖ Precompile regex, check FIRST

### 8. Streaming Strategy

**Impact:** PERCEIVED latency (–Ω–µ real)
**Trade-off:** Complexity vs UX

‚öñÔ∏è **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# Fast path –¥–ª—è simple ‚Üí immediate stream
if complexity == SIMPLE:
    return "immediate"
# Show thinking for complex
return "delayed" if complexity == COMPLEX else "immediate"
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚úÖ Default to immediate, exception for deep

### 9. Caching Strategy

**Impact:** MEMORY trade-off
**Trade-off:** +10-50MB RAM vs faster repeat queries

‚öñÔ∏è **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# LRU Cache —Å TTL
from functools import lru_cache
from cachetools import TTLCache

routing_cache = TTLCache(maxsize=100, ttl=300)  # 5 min, 100 entries
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚úÖ Bounded LRU (max 100 entries, ~10MB)

### 10. Safety Filter

**Impact:** ~10ms (pattern matching)
**Trade-off:** Security > Speed

‚öñÔ∏è **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# Set lookup O(1) –≤–º–µ—Å—Ç–æ list O(n)
DANGEROUS_PATTERNS = {"rm -rf", "format", "delete all", "DROP TABLE"}
needs_confirm = any(p in message for p in DANGEROUS_PATTERNS)
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚úÖ Use set + early exit

---

## üß† UX BOOST (2 —Ñ–∏—á–∏)

### 11. Parallel Decomposition

**Impact:** +100-200ms –¥–ª—è decomposition, BUT parallel execution is faster overall

üß† **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# Only decompose if ACTUALLY complex
if complexity != COMPLEX or word_count < 50:
    return single_task  # Skip decomposition overhead

# Use existing fan_out.py
results = await fan_out_tasks(sub_tasks, max_parallel=2)
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚úÖ Only for genuinely complex tasks

### 12. Emotional Tone

**Impact:** +50-100ms (LLM call required)
**UX Benefit:** Better rapport

üß† **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**

```python
# DEFER: Do emotion detection AFTER routing, not blocking
# Use CPU heuristics first, LLM only for ambiguous
if "?" in message and any(w in message for w in ["—É—Å—Ç–∞–ª", "—Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç"]):
    tone = "empathetic"
else:
    tone = "neutral"  # Default, override later
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚è≠Ô∏è DEFER to Phase 3, use heuristics

---

## üìä NEEDS MEASUREMENT (2 —Ñ–∏—á–∏)

### 13. User Preference Learning

**Impact:** Unknown (DB query)
**Risk:** Could add 50-200ms if not cached

üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

1. Measure DB query time
2. Pre-load preferences at session start
3. Cache in memory

### 14. Model Selector

**Impact:** Unknown (depends on LM Studio model switching)
**Risk:** Model load time can be 5-30 SECONDS

üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

1. Test model switching latency in LM Studio
2. If slow ‚Üí keep single model loaded
3. If fast ‚Üí implement warm model pool

---

## üö´ ANTI-PATTERN WARNINGS

### ‚ùå Don't: LLM call for every feature

```python
# BAD: 15 LLM calls = 7500ms latency
intent = await llm_router.route(msg)  # 500ms
safety = await llm_check_safety(msg)  # 500ms
emotion = await llm_detect_emotion(msg)  # 500ms
# ...
```

### ‚úÖ Do: Single LLM call + CPU post-processing

```python
# GOOD: 1 LLM call + CPU calculations = 550ms
decision = await llm_router.route(msg)  # 500ms

# CPU only (0ms each)
temperature = TEMP_MAP[decision.intent]
mode = decision.suggested_mode
safety = cpu_check_safety(msg)
# ...
```

---

## üìã –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ü–æ—Ä—è–¥–æ–∫ –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### Phase 1: ZERO/NEGATIVE Latency (—Å—Ä–∞–∑—É)

```
1. Auto Mode Selection      ‚Üí 0ms (proxy)
2. Temperature Auto-Tune    ‚Üí 0ms (lookup)
3. RAG Trigger              ‚Üí -100ms (skip saves time)
4. Context Window Optimizer ‚Üí -50ms (fewer tokens)
5. Cost Estimator           ‚Üí 0ms (calculate)
```

### Phase 2: Smart Trade-offs (—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏)

```
6. Privacy Lock             ‚Üí 5ms (compiled regex, first check)
7. Streaming Strategy       ‚Üí 0ms (decision only)
8. Caching Strategy         ‚Üí +10MB RAM, -500ms repeats
9. Safety Filter            ‚Üí 10ms (set lookup)
10. LLM Router Cache        ‚Üí -400ms for repeats
```

### Phase 3: Measure First

```
11. Parallel Decomposition  ‚Üí MEASURE before implementing
12. User Preferences        ‚Üí MEASURE DB latency
13. Model Selector          ‚Üí MEASURE LM Studio switch time
14. Emotional Tone          ‚Üí DEFER, use CPU heuristics
```

---

## üéØ –ò—Ç–æ–≥–æ–≤—ã–µ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

| Action | Impact |
|--------|--------|
| Add LLM Router cache | **-400ms** (90% repeats) |
| Add timeout fallback | **Zero worst-case** (CPU fallback) |
| Skip RAG for simple | **-100ms** per simple query |
| Use set for patterns | **O(1)** instead of O(n) |
| Batch features in single call | **-4000ms** vs naive |
| Defer emotional tone | **-100ms** Phase 1 |

**–û–∂–∏–¥–∞–µ–º—ã–π –±—é–¥–∂–µ—Ç SmartRouter:**

- Best case (cached): **~50ms**
- Average case: **~500ms** (LLM call)
- Worst case (fallback): **~100ms** (CPU router)

‚úÖ –£–∫–ª–∞–¥—ã–≤–∞–µ–º—Å—è –≤ –±—é–¥–∂–µ—Ç **< 200ms average** —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º!
