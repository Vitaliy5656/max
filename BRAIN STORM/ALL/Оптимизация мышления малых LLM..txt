Архитектура когнитивной оркестрации для локальных LLM: Реализация System 2 мышления в ограничениях 16 ГБ VRAM
1. Введение: Смена парадигмы от обучения к инференсу
Индустрия искусственного интеллекта переживает фундаментальный сдвиг, который можно охарактеризовать как переход от «масштабирования параметров» к «масштабированию вычислений во время вывода» (Inference-Time Compute). Долгое время доминировала гипотеза, что сложные рассуждения являются эмерджентным свойством, возникающим исключительно при увеличении количества параметров модели до сотен миллиардов. Однако последние исследования и релизы, такие как OpenAI o1 и DeepSeek-R1, доказали, что модели меньшего размера могут демонстрировать сверхчеловеческие способности к рассуждению, если им предоставить возможность «подумать» перед ответом.1
Для разработчиков, работающих с локальными моделями в диапазоне 7B-14B параметров на потребительском оборудовании (например, с ограничением в 16 ГБ видеопамяти), это открывает беспрецедентные возможности. Вместо того чтобы пытаться запустить гигантскую модель, которая не помещается в память, мы можем использовать архитектурные решения — оркестраторы, — чтобы заставить компактную модель работать в режиме System 2 (медленное, логическое мышление), компенсируя недостаток «интеллекта параметров» избытком «интеллекта процесса».3
Ваша задача по рефакторингу кода для внедрения механизмов самокритики и глубокого размышления является не просто оптимизацией, а переходом к агентной архитектуре. В этом отчете мы детально разберем, как построить Локальный Оркестратор Рассуждений, который превратит 14-миллиардную модель из генератора текста в надежный аналитический движок. Мы рассмотрим аппаратные ограничения, алгоритмы квантования, паттерны оркестрации (LangGraph), методы сэмплирования (Entropix) и стратегии структурированной декодировки (Outlines/Guidance), необходимые для реализации этого решения.
________________
2. Теоретические основы System 2 в языковых моделях
Чтобы эффективно спроектировать оркестратор, необходимо глубоко понимать когнитивные ограничения стандартных трансформеров и механизмы, позволяющие их преодолеть.
2.1. Дихотомия Канемана в контексте LLM
Нобелевский лауреат Даниэль Канеман ввел различие между двумя режимами мышления, которое стало концептуальной основой для современных архитектур рассуждений в ИИ.2
* System 1 (Быстрое мышление): Стандартная авторегрессионная генерация LLM работает именно в этом режиме. Модель предсказывает следующий токен на основе поверхностных статистических ассоциаций, заложенных во время обучения. Для моделей размера 7B-14B это проявляется в высокой беглости речи, но низкой фактической точности и логической связности на длинных дистанциях. Модель «интуитивно» выбрасывает ответ, не имея возможности проверить его корректность до момента генерации.
* System 2 (Медленное мышление): Это режим осознанного, последовательного рассуждения, включающий планирование, декомпозицию задачи и верификацию промежуточных результатов. В LLM этот режим не является нативным; он должен быть индуцирован извне. Поскольку у модели нет скрытого «рабочего пространства» для мыслей (все активации исчезают после генерации токена), мы должны заставить модель экстернализировать свои мысли в контекстное окно.
Роль Оркестратора: Оркестратор выполняет функцию Исполнительного контроля (Executive Function) биологического мозга. Он прерывает быстрый поток System 1, заставляя модель генерировать цепочки рассуждений (Chain of Thought - CoT), критиковать их и пересматривать решения при обнаружении ошибок. Для моделей 7B-14B, которые склонны «терять нить» рассуждений, наличие жесткого внешнего цикла управления является критически важным.6
2.2. Закон масштабирования вычислений во время вывода (Test-Time Compute)
Эмпирические данные, полученные при анализе моделей типа DeepSeek-R1-Zero и OpenAI o1, демонстрируют новый закон масштабирования: точность решения сложных задач (математика, кодинг, логика) логарифмически возрастает с увеличением количества токенов, сгенерированных в процессе рассуждения.1
Параметр масштабирования
	Описание
	Влияние на 14B модель
	Параметры модели
	Фиксировано архитектурой (обучение)
	Ограничено 16 ГБ VRAM (нет возможности масштабирования).
	Данные обучения
	Фиксировано чекпоинтом
	Использование дистиллированных моделей (DeepSeek-R1-Distill) повышает базу.
	Токены рассуждения
	Динамический ресурс (инференс)
	Основной рычаг управления. Позволяет тратить время GPU на поиск верного решения.
	Это обосновывает экономическую и техническую целесообразность использования оркестратора на локальном железе. Мы не можем загрузить модель на 70B параметров, но мы можем позволить модели на 14B параметров «думать» в течение 30-60 секунд, генерируя тысячи промежуточных токенов, верифицируя гипотезы и исправляя ошибки, чтобы достичь качества ответа, сопоставимого с более крупными моделями.3
2.3. Роль Reinforcement Learning (RL) и дистилляции
Прорывные модели рассуждений обучаются с использованием крупномасштабного обучения с подкреплением (RL), где модель получает награду за правильный конечный ответ, самостоятельно вырабатывая стратегии поиска ошибок и перепроверки.8
Для локальных задач мы используем результаты этого процесса двумя способами:
1. Использование дистиллятов: Мы выбираем модели (например, QwQ-32B или DeepSeek-R1-Distill-Qwen-14B), которые были обучены на траекториях рассуждений «больших» моделей. Они уже имеют предрасположенность к структурированному мышлению (теги <think>), что облегчает работу оркестратора.10
2. Эмуляция RL в рантайме: Оркестратор может симулировать процесс RL, выступая в роли внешней среды, которая дает сигналы «Успех/Неудача» (например, через запуск кода или проверку формата) и заставляет модель обновлять стратегию в рамках одного контекста.1
________________
3. Аппаратные ограничения и выбор стратегии квантования
Прежде чем переходить к архитектуре ПО, необходимо жестко определить границы возможностей оборудования. 16 ГБ видеопамяти — это «золотая середина» для энтузиастов, но она требует строгой дисциплины в управлении ресурсами.
3.1. Математика VRAM для моделей 14B
Для запуска модели необходимо разместить в видеопамяти не только веса модели, но и KV-кэш (контекст), а также буфер для активаций.
Расчет для модели 14B (например, Qwen 2.5 14B):
* FP16 (Half Precision): 14 млрд $\times$ 2 байта = 28 ГБ. Невозможно запустить на 16 ГБ.
* Q4_K_M (4-битное квантование GGUF): 14 млрд $\times$ ~0.6-0.65 байта (с учетом метаданных) $\approx$ 9.5 - 10 ГБ.
Это оставляет нам около 6 ГБ свободного пространства. На что оно расходуется?
1. KV-кэш (Контекстное окно): Это память, необходимая для хранения ключей и значений механизма внимания. При длине контекста 8192 токена (стандарт для сложных рассуждений) в 16-битном формате это заняло бы ~4-5 ГБ.
2. Активации и временные буферы: ~0.5 - 1 ГБ.
3. Оверхед системы: Операционная система и интерфейс дисплея могут занимать 1-2 ГБ.
Вывод: Чтобы уместить 14B модель с приличным контекстом (8k-16k) в 16 ГБ, необходимо использовать не только квантование весов, но и квантование KV-кэша (например, 8-bit или 4-bit cache) и технологии Flash Attention.12
3.2. Битва форматов: GGUF против EXL2
Для построения оркестратора выбор формата модели критичен.
Характеристика
	GGUF (llama.cpp)
	EXL2 (ExLlamaV2)
	Рекомендация для Оркестратора
	Скорость (Tokens/sec)
	Средняя (зависит от оффлоада)
	Максимальная (оптимизировано под GPU)
	GGUF (для стабильности)
	Управление памятью
	Умный оффлоад: Если контекст переполняет VRAM, слои прозрачно выгружаются в RAM. Скорость падает, но приложение не падает.
	Жесткий лимит: Если VRAM заканчивается, возникает OOM (Out of Memory) ошибка.
	GGUF
	Поддержка квантования
	Широкая (включая I-quants)
	Гибкая (переменный битрейт)
	GGUF (Q4_K_M — стандарт качества)
	Экосистема
	Интеграция с Ollama, LangChain
	Требует специальных загрузчиков (Tabby, Oobabooga)
	GGUF (через Ollama)
	Для задач рассуждения, где длина цепочки мыслей может непредсказуемо расти (иногда достигая 10-15 тысяч токенов), использование GGUF является более безопасным выбором. Оно предотвращает крах всего пайплайна при выходе за пределы 16 ГБ, жертвуя скоростью в пользу надежности.14
3.3. Рекомендуемые модели класса 7B-14B
На текущий момент (2025 год) ландшафт моделей в этом классе изменился в пользу специализированных моделей.
1. Qwen 2.5 14B (Instruct): Абсолютный лидер в классе по математике и кодингу. Огромный объем обучающих данных по точным наукам делает ее идеальным кандидатом для System 2 логики. Хорошо поддается квантованию.16
2. DeepSeek-R1-Distill-Qwen-14B: Это модель Qwen 14B, дообученная на цепочках рассуждений "старшей" модели DeepSeek-R1. Она нативно поддерживает формат <think>, что упрощает создание системных промптов для оркестратора.9
3. Mistral-Nemo 12B: Совместная разработка с NVIDIA. Отличается очень длинным контекстом (128k), но требует тщательной проверки на «забывание» инструкций при длинных цепочках рассуждений.
________________
4. Архитектурные паттерны когнитивной оркестрации
Реализация «размышлений» требует выхода за рамки линейной генерации (Input -> Model -> Output). Мы должны перейти к циклическим графам обработки информации.
4.1. Паттерн «Генератор — Верификатор — Рефайнер» (Generator-Verifier-Refiner)
Это фундаментальный паттерн для реализации самокритики. В стандартном вызове LLM генерация и проверка смешаны, что приводит к галлюцинациям. Оркестратор разделяет их во времени.
Этапы цикла:
1. Генерация (Drafting): Модель получает задачу и инструкцию использовать структурированный формат (например, XML теги <plan>, <step>, <analysis>). Она генерирует предварительное решение.
2. Верификация (Verification): Оркестратор останавливает процесс, берет сгенерированный текст и скармливает его обратно модели (или другой «персоне» той же модели) с промптом: «Проверь приведенное выше решение на логические ошибки, арифметические неточности и соответствие условиям задачи. Если есть ошибки, укажи их. Если нет, напиши VALID».
3. Уточнение (Refinement): Если верификатор нашел ошибки, контекст (включая критику) передается обратно генератору с инструкцией: «Предыдущее решение было неверным по следующим причинам: [Критика]. Перепиши решение, исправив эти ошибки».
Этот цикл повторяется до тех пор, пока верификатор не примет ответ или не будет исчерпан лимит итераций (например, 3-5 циклов).18
4.2. Chain of Verification (CoVe): Атомарная проверка фактов
Для борьбы с галлюцинациями в 7B-14B моделях (которые часто выдумывают факты) паттерн CoVe разбивает проверку на атомарные вопросы.20
Алгоритм реализации:
1. Базовая генерация: Модель дает ответ на запрос пользователя.
2. Планирование проверки: Оркестратор просит модель: «Сгенерируй список вопросов (да/нет), ответы на которые необходимы для подтверждения фактов в твоем ответе выше».
3. Исполнение проверки: Модель (независимо от первого ответа) отвечает на каждый сгенерированный вопрос. Здесь можно использовать пониженную температуру (0.1) для максимальной фактологичности.
4. Сличение: Оркестратор просит модель сравнить исходный ответ с ответами на проверочные вопросы.
5. Финализация: Если есть противоречия, генерируется исправленный ответ.
Этот метод дорог по токенам, но критически важен для задач, требующих фактической точности (RAG, анализ документов).
4.3. Динамическое промптирование «g1» и мета-когнитивные стратегии
Проект «g1» продемонстрировал, что даже без дообучения можно значительно улучшить рассуждения, используя динамические системные промпты, которые заставляют модель исследовать альтернативы.23
Суть метода:
Системный промпт не просто просит «решить задачу», а навязывает когнитивную стратегию:
* «Ты должен предложить как минимум 3 разных метода решения этой задачи».
* «Для каждого метода напиши критику и оцени его вероятность успеха».
* «Синтезируй финальный ответ на основе лучших частей предложенных методов».
Для 14B моделей это работает как «костыль» для рабочей памяти. Заставляя модель писать альтернативы, мы увеличиваем вероятность того, что правильная логическая цепочка окажется в контексте и будет "подхвачена" механизмом внимания при генерации финального ответа.25
4.4. Мульти-агентная дискуссия (Debate)
Поскольку мы ограничены 16 ГБ VRAM, мы не можем запустить две разные модели 14B одновременно. Однако мы можем использовать переключение персон (Persona Swapping) в рамках одной модели.
Реализация:
1. Агент А (Оптимист): Генерирует решение.
2. Смена контекста: Оркестратор сохраняет ответ А, очищает контекст и загружает системный промпт Агента Б.
3. Агент Б (Пессимист/Критик): Получает задачу и решение А. Его цель — найти ошибку.
4. Синтез: Третий прогон, где «Судья» взвешивает аргументы А и Б.
Исследования показывают, что такой подход помогает преодолеть «слепоту» модели к собственным ошибкам, так как смена системного промпта меняет распределение вероятностей генерации.26
________________
5. Алгоритмические интервенции: Сэмплирование и Декодинг
Оркестратор может управлять не только промптами, но и тем, как модель выбирает следующий токен. Это самый низкоуровневый и мощный способ улучшения рассуждений.
5.1. Entropix: Сэмплирование на основе энтропии
Стандартное сэмплирование (Temperature, Top-P) статично. Технология Entropix предлагает динамически менять стратегию выбора токена в зависимости от неуверенности модели.28
Метрики:
* Энтропия (Entropy): Насколько модель "не уверена" в следующем токене. Высокая энтропия = плоское распределение вероятностей (много вариантов).
* Варентропия (Varentropy): Дисперсия энтропии. Показывает, колеблется ли модель между несколькими сильными вариантами или просто «не знает».
Стратегия Оркестратора:
Мы должны перехватывать логиты (logits) модели перед генерацией токена (это возможно через llama-cpp-python или API, отдающие logprobs).
Состояние модели
	Характеристика
	Действие Оркестратора
	Низкая Энтропия
	Модель уверена. Простые слова, факты.
	Argmax (Greedy): Выбирать самый вероятный токен. Исключить случайность.
	Высокая Энтропия, Низкая Варентропия
	Модель в замешательстве, нет явного лидера.
	Вставка CoT: Принудительно вставить токен переноса строки или фразу "Wait," или "Let's think", чтобы переключить модель в режим рассуждения.
	Высокая Энтропия, Высокая Варентропия
	Модель видит развилку (несколько валидных путей).
	Ветвление (Branching): Сгенерировать 2-3 варианта продолжения (параллельные ветки) и оценить их позже.
	Для 14B модели это критически важно. Маленькие модели часто «сваливаются» в неверную ветку рассуждений из-за неудачного броска костей при сэмплировании. Entropix позволяет детектировать эти моменты.31
5.2. Структурированный Декодинг (Constrained Decoding)
Одной из проблем System 2 на маленьких моделях является соблюдение формата. Если мы просим модель вывести JSON, а она срывается в текст, пайплайн ломается.
Инструменты Outlines и Guidance решают эту проблему, манипулируя маской логитов. Они запрещают модели генерировать токены, которые нарушают заданную грамматику (Regex, JSON Schema).33
Применение в Оркестраторе:
Вместо того чтобы надеяться, что модель послушается промпта, мы гарантируем это технически.
* Мы определяем схему ответа: Step (string), Critique (string), Confidence (float).
* Библиотека Outlines перехватывает процесс генерации и, если модель находится внутри поля Confidence, разрешает только цифры.
* Это разгружает «мозг» модели 14B. Ей не нужно тратить ресурсы внимания на форматирование скобок, она может сосредоточиться на смысле.33
________________
6. Реализация: Создание «Локального Движка Рассуждений»
Перейдем от теории к практике рефакторинга. Мы будем использовать LangGraph как фреймворк, так как он нативно поддерживает циклические графы и персистентность состояния, в отличие от линейных цепочек LangChain.36
6.1. Стек технологий
* Inference Engine: Ollama (как сервер) или Llama.cpp (через Python bindings для доступа к логитам). Ollama предпочтительнее для простоты интеграции, Llama.cpp — для реализации Entropix.
* Orchestration: LangGraph (Python).
* Constraints: Outlines (интегрированный в вызов генерации).
* Model: Qwen2.5-14B-Instruct-Q4_K_M.gguf.
6.2. Архитектура Графа (StateGraph)
Мы определяем состояние агента, которое будет передаваться между узлами графа.


Python




from typing import TypedDict, List, Annotated
import operator

class AgentState(TypedDict):
   input: str                  # Запрос пользователя
   plan: str                   # План решения
   steps: List[str]            # Пройденные шаги
   draft_answer: str           # Текущий черновик
   critique: str               # Текст критики
   score: float                # Оценка качества (0-1)
   iterations: int             # Счетчик циклов
   past_failures: List[str]    # История ошибок (для контекста)

Узлы Графа (Nodes):
1. Planner Node:
   * Input: input
   * Action: Использует модель для декомпозиции задачи на подзадачи.
   * System Prompt: "Ты стратег. Разбей задачу на атомарные шаги."
2. Executor Node (Reasoning):
   * Input: plan, past_failures
   * Action: Генерирует решение (или следующий шаг). Использует <think> теги (как в DeepSeek-R1).
   * Constraint: Outlines JSON Schema { "thought": str, "action": str, "output": str }.
3. Reflector Node (Critic):
   * Input: draft_answer
   * Action: Оценивает решение.
   * System Prompt: "Ты строгий рецензент. Найди ошибки. Если решение верно, поставь оценку 1.0."
4. Memory Node (Summarizer):
   * Критический узел для 16 ГБ VRAM.
   * Logic: Если цикл повторяется, мы не можем накапливать весь текст предыдущих попыток. Этот узел берет critique и draft_answer неудачной попытки и сжимает их в past_failures: "Попытка №1 использовала метод X, но ошиблась в расчете Y."
   * Очищает steps и draft_answer перед возвратом к Executor.
Ребра (Edges):
* Executor -> Reflector
* Reflector -> (Conditional Edge):
   * Если score > 0.9 -> END (Успех).
   * Если score <= 0.9 И iterations < 5 -> Memory Node -> Executor (Повтор).
   * Если iterations >= 5 -> END (Возврат лучшего из имеющихся или сообщение об ошибке).
6.3. Реализация "g1" промптинга внутри Графа
В узле Executor мы внедряем динамический системный промпт, эмулирующий поведение o1.
SYSTEM PROMPT:
Вы — продвинутый движок рассуждений. Ваша цель — решить задачу пользователя, используя глубокое размышление.
1. НАЧНИТЕ с тега . Внутри этого тега вы должны:
   * Проанализировать запрос.
   * Предложить несколько гипотез.
   * Опровергнуть неверные гипотезы.
   * Выработать пошаговый план.
2. ВЫВОДИТЕ решение только после завершения процесса мышления.
3. Используйте технику "Разделяй и властвуй" для сложных задач.
Если модель Qwen 2.5 14B "ленится" и сразу выдает ответ, оркестратор (проверка на Python) должен определить отсутствие тега <think>, отбросить ответ и повторить запрос с добавлением: «Вы нарушили протокол. Начните ответ с размышления в тегах ».8
6.4. Управление памятью и VRAM
Самая большая проблема при рекурсивном рассуждении на локальной машине — переполнение контекста, которое приводит к падению производительности (из-за свопинга) или ошибке OOM.
Стратегии для 16 ГБ:
1. Агрессивное саммари: Никогда не подавайте в модель полную историю всех неудачных итераций. Только сжатое резюме ошибок. Это держит использование KV-кэша плоским, независимо от количества итераций.39
2. Очистка кэша: При переходе между узлами (например, от Executor к Reflector), если они используют разные системные промпты, KV-кэш может стать невалидным или фрагментированным. В библиотеках типа llama-cpp-python может потребоваться явный вызов reset() или управление слотами кэша.
3. Квантованный Кэш (KVCache Quantization): Включите опцию flash_attn и cache_type_k="q8_0", cache_type_v="q8_0" в загрузчике модели. Это снизит потребление памяти контекстом в 2 раза с минимальной потерей качества, что критично для длинных цепочек рассуждений (10k+ токенов).12
________________
7. Сравнительный анализ моделей и ожидаемая производительность
Что ожидать от такой системы?
7.1. Бенчмаркинг оркестрированных SLM
Исследования показывают, что применение методов самокоррекции (Self-Correction) и иерархического промптинга (SuperCorrect) позволяет моделям 7B-14B превосходить модели класса 70B, работающие в режиме zero-shot (без рассуждений).
* Математика (MATH/GSM8K): Qwen 2.5 14B с оркестрацией достигает уровня GPT-4o-mini. Без оркестрации она значительно слабее.
* Логические загадки («Strawberry Problem»): Стандартные модели часто ошибаются (считая буквы в слове). Оркестрированная модель, заставляющая написать слово по буквам и пронумеровать их в блоке <think>, решает задачу с точностью >90%.24
* Кодинг (HumanEval): Цикл «Напиши код -> Запусти тест -> Получи ошибку -> Исправь» (Reflexion) позволяет решать задачи Hard-уровня, недоступные для однопроходной генерации.
7.2. Плата за интеллект: Латентность
Пользователь должен понимать, что внедрение System 2 радикально меняет UX.
* Zero-shot: Ответ за 2-3 секунды.
* Orchestrated: Ответ может занимать 30-90 секунд.
* UX Решение: Критически важно стримить пользователю процесс «мышления» (содержимое тегов <think>). Это создает ощущение работы над сложной задачей и удерживает внимание, как это сделано в интерфейсе ChatGPT o1.23
________________
8. Будущее направление: Агентные системы как ПО
Ваша работа по рефакторингу кода — это шаг в сторону будущего, где LLM перестает быть «черным ящиком», выдающим текст, и становится модульным компонентом сложной программной системы.
Перспективы развития вашего оркестратора:
1. Интеграция RAG: В фазе планирования модель может запросить поиск по локальной базе знаний. Оркестратор выполнит поиск и вернет чанки. Это превращает систему в мощный аналитический инструмент.41
2. Fine-tuning для Оркестрации: В будущем вы можете собрать датасет из успешных цепочек рассуждений вашего оркестратора и дообучить (SFT) маленькую модель (например, 7B) именно на этот формат, еще больше повысив эффективность и снизив задержки (метод Expert Iteration).43
3. Гибридное сэмплирование: Полная интеграция Entropix на уровне C++ бэкенда (llama.cpp) позволит оркестратору «чувствовать» неуверенность модели без лишних запросов, автоматически включая ветвление только там, где это необходимо.28
________________
9. Заключение и План действий
Для реализации задачи «заставить модель реально размышлять» в условиях 16 ГБ VRAM, вам необходимо перейти от линейного вызова API к агентной архитектуре на базе графов.
Итоговый рецепт:
1. Модель: Используйте Qwen 2.5 14B Instruct (или DeepSeek-R1-Distill) в квантовании Q4_K_M формата GGUF. Это даст оптимальный баланс «интеллекта» и доступной памяти для контекста.
2. Фреймворк: Внедрите LangGraph. Это позволит создать надежный цикл Generate -> Verify -> Refine.
3. Промптинг: Реализуйте стратегию "g1" (динамический системный промпт), принуждающую к использованию тегов <think> и пошаговой декомпозиции.
4. Контроль: Используйте Outlines для жесткой типизации вывода (JSON), чтобы программный код мог надежно парсить вердикт верификатора.
5. Память: Реализуйте узел Саммаризации ошибок, чтобы не раздувать контекст при итерациях.
Это решение превращает ограничения железа в стимул для создания более совершенной архитектуры, способной к глубокому анализу и самокоррекции.
Источники
1. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning - arXiv, дата последнего обращения: декабря 13, 2025, https://arxiv.org/pdf/2501.12948
2. From System 1 to System 2: A Survey of Reasoning Large Language Models - PubMed, дата последнего обращения: декабря 13, 2025, https://pubmed.ncbi.nlm.nih.gov/41289126/
3. Enhancing Reasoning Abilities of Small LLMs with Cognitive Alignment - ACL Anthology, дата последнего обращения: декабря 13, 2025, https://aclanthology.org/2025.emnlp-main.377.pdf
4. Enhancing Math Reasoning in Small-sized LLMs via Preview Difficulty-Aware Intervention, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2508.01604v1
5. [2502.17419] From System 1 to System 2: A Survey of Reasoning Large Language Models, дата последнего обращения: декабря 13, 2025, https://arxiv.org/abs/2502.17419
6. A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems | OpenReview, дата последнего обращения: декабря 13, 2025, https://openreview.net/forum?id=SlsZZ25InC
7. open-thought/system-2-research: System 2 Reasoning Link Collection - GitHub, дата последнего обращения: декабря 13, 2025, https://github.com/open-thought/system-2-research
8. deepseek-ai/DeepSeek-R1 - Hugging Face, дата последнего обращения: декабря 13, 2025, https://huggingface.co/deepseek-ai/DeepSeek-R1
9. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2501.12948v1
10. [2504.04823] Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models - arXiv, дата последнего обращения: декабря 13, 2025, https://arxiv.org/abs/2504.04823
11. Running an Open-Source Reasoning Model locally - Niklas Heidloff, дата последнего обращения: декабря 13, 2025, https://heidloff.net/article/reasoning-ollama/
12. Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models - arXiv, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2504.04823v1
13. Context Kills VRAM: How to Run LLMs on consumer GPUs | by Lyx | Medium, дата последнего обращения: декабря 13, 2025, https://medium.com/@lyx_62906/context-kills-vram-how-to-run-llms-on-consumer-gpus-a785e8035632
14. Comprehensive benchmark of GGUF vs EXL2 performance across multiple models and sizes : r/LocalLLaMA - Reddit, дата последнего обращения: декабря 13, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1e68k4o/comprehensive_benchmark_of_gguf_vs_exl2/
15. Is it possible that exl2 would produce better output than gguf of same size? : r/Oobabooga, дата последнего обращения: декабря 13, 2025, https://www.reddit.com/r/Oobabooga/comments/1f7jx0g/is_it_possible_that_exl2_would_produce_better/
16. Qwen/Qwen2.5-14B - Hugging Face, дата последнего обращения: декабря 13, 2025, https://huggingface.co/Qwen/Qwen2.5-14B
17. How good are the new 14b and 32b qwen2.5 models ? : r/LocalLLaMA - Reddit, дата последнего обращения: декабря 13, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1g6fa24/how_good_are_the_new_14b_and_32b_qwen25_models/
18. Small Language Models Need Strong Verifiers to Self-Correct Reasoning - ACL Anthology, дата последнего обращения: декабря 13, 2025, https://aclanthology.org/2024.findings-acl.924.pdf
19. SuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2410.09008v2
20. Chain-of-Verification: Can models become more accurate by talking to themselves? | by Will, дата последнего обращения: декабря 13, 2025, https://medium.com/@Willibles/chain-of-verification-can-models-become-more-accurate-by-talking-to-themselves-cf3325c6913e
21. Chain-of-Verification Reduces Hallucination in Large Language Models - ACL Anthology, дата последнего обращения: декабря 13, 2025, https://aclanthology.org/2024.findings-acl.212.pdf
22. Chain-of-Verification (CoVe): Reduce LLM Hallucinations - Learn Prompting, дата последнего обращения: декабря 13, 2025, https://learnprompting.org/docs/advanced/self_criticism/chain_of_verification
23. G1: Using Llama-3.1 70b on Groq to create o1-like Reasoning Chains - YouTube, дата последнего обращения: декабря 13, 2025, https://www.youtube.com/watch?v=xOwdGRXa5Xg
24. win4r/o1: Using Groq or OpenAI or Ollama to create o1-like ... - GitHub, дата последнего обращения: декабря 13, 2025, https://github.com/win4r/o1
25. OpenAI o1 now has an OpenSource Replica - unwind ai, дата последнего обращения: декабря 13, 2025, https://www.theunwindai.com/p/openai-o1-now-has-an-opensource-replica
26. We just released a multi-agent framework. Please break it. : r/ollama - Reddit, дата последнего обращения: декабря 13, 2025, https://www.reddit.com/r/ollama/comments/1opat7j/we_just_released_a_multiagent_framework_please/
27. Building AI Workflows with LangGraph: Practical Use Cases and Examples - Scalable Path, дата последнего обращения: декабря 13, 2025, https://www.scalablepath.com/machine-learning/langgraph
28. Sample Smart, Not Hard: Correctness-First Decoding for Better Reasoning in LLMs - arXiv, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2510.05987v1
29. Entropixplained | Southbridge - Notion, дата последнего обращения: декабря 13, 2025, https://southbridge-research.notion.site/Entropixplained-11e5fec70db18022b083d7d7b0e93505
30. Entropix: Sampling Techniques for Maximizing Inference Performance - DEV Community, дата последнего обращения: декабря 13, 2025, https://dev.to/m_sea_bass/entropix-sampling-techniques-for-maximizing-inference-performance-2hgc
31. Detecting when LLMs are Uncertain - Thariq Shihipar, дата последнего обращения: декабря 13, 2025, https://www.thariq.io/blog/entropix/
32. Entropix: Sampling Techniques for Maximizing Inference Performance | by M Sea Bass, дата последнего обращения: декабря 13, 2025, https://medium.com/@m_sea_bass/entropix-sampling-techniques-for-maximizing-inference-performance-a422d65b6c65
33. Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation - arXiv, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2403.06988v1
34. dottxt-ai/outlines: Structured Outputs - GitHub, дата последнего обращения: декабря 13, 2025, https://github.com/dottxt-ai/outlines
35. Introducing Structured Outputs in the API - OpenAI, дата последнего обращения: декабря 13, 2025, https://openai.com/index/introducing-structured-outputs-in-the-api/
36. Memory overview - Docs by LangChain, дата последнего обращения: декабря 13, 2025, https://docs.langchain.com/oss/python/langgraph/memory
37. LangGraph overview - Docs by LangChain, дата последнего обращения: декабря 13, 2025, https://docs.langchain.com/oss/python/langgraph/overview
38. The Complete Guide to DeepSeek Models: V3, R1, V3.1, V3.2 and Beyond - BentoML, дата последнего обращения: декабря 13, 2025, https://www.bentoml.com/blog/the-complete-guide-to-deepseek-models-from-v3-to-r1-and-beyond
39. Reducing length of State in LangGraph : r/LangChain - Reddit, дата последнего обращения: декабря 13, 2025, https://www.reddit.com/r/LangChain/comments/1ei7fvd/reducing_length_of_state_in_langgraph/
40. Building a Smarter Agent with LangGraph: Short-Term Memory and Context Engineering | KBTG Life - Medium, дата последнего обращения: декабря 13, 2025, https://medium.com/kbtg-life/building-a-smarter-agent-with-langgraph-a-guide-to-short-term-memory-and-context-engineering-25b1f7ae155d
41. Improving the Reliability of LLMs: Combining Chain-of-Thought Reasoning and Retrieval-Augmented Generation - arXiv, дата последнего обращения: декабря 13, 2025, https://arxiv.org/html/2505.09031v1
42. Longer context ≠ better: Why RAG still matters - Elasticsearch Labs, дата последнего обращения: декабря 13, 2025, https://www.elastic.co/search-labs/blog/rag-vs-long-context-model-llm
43. zzli2022/Awesome-System2-Reasoning-LLM: Latest Advances on System-2 Reasoning - GitHub, дата последнего обращения: декабря 13, 2025, https://github.com/zzli2022/Awesome-System2-Reasoning-LLM