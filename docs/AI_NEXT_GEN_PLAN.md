# MAX AI: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –£–º–Ω–æ–≥–æ –ü–æ–≤–µ–¥–µ–Ω–∏—è v3.5

**–í–µ—Ä—Å–∏—è:** 3.5 (Architect Recommendations Integrated)
**–î–∞—Ç–∞:** 2025-12-12
**–°—Ç–∞—Ç—É—Å:** –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø–ª–∞–Ω —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–∞
**–ê–≤—Ç–æ—Ä:** Senior Solutions Architect

---

## Executive Summary

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é MAX –∏–∑ "—Ü–µ–ø–æ—á–∫–∏ –ø—Ä–æ–º–ø—Ç–æ–≤" –≤ **–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—É—é –°–∏—Å—Ç–µ–º—É —Å –°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π**, —Å —É—á—ë—Ç–æ–º **–ø–æ–ª–Ω–æ–π —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã** –ø—Ä–æ–µ–∫—Ç–∞.

### –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π —Å—Ç–µ–∫ MAX

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    –¢–ï–ö–£–©–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê MAX                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ UserProfile ‚îÇ  ‚îÇ Adaptation  ‚îÇ  ‚îÇ MetricsEng  ‚îÇ  ‚îÇ  Memory   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (mood,prefs)‚îÇ  ‚îÇ (learn)     ‚îÇ  ‚îÇ (IQ/EQ)     ‚îÇ  ‚îÇ (multi)   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                ‚îÇ               ‚îÇ         ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                              ‚îÇ                                      ‚îÇ
‚îÇ                              ‚ñº                                      ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ                    ‚îÇ   LM Client     ‚îÇ                              ‚îÇ
‚îÇ                    ‚îÇ (detect_task)   ‚îÇ                              ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îÇ                             ‚îÇ                                       ‚îÇ
‚îÇ                             ‚ñº                                       ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ                    ‚îÇ   AutoGPT       ‚îÇ                              ‚îÇ
‚îÇ                    ‚îÇ (agent loop)    ‚îÇ                              ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ù–æ–≤—ã–µ –º–æ–¥—É–ª–∏ (—ç—Ç–æ—Ç –ø–ª–∞–Ω)

| –ú–æ–¥—É–ª—å | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å | –§—É–Ω–∫—Ü–∏—è |
|--------|--------------|---------|
| **SafeShell** | `tools.py` | Windows-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –∫–æ–º–∞–Ω–¥—ã |
| **ReflectiveAgent** | `autogpt.py`, `MetricsEngine` | –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏–π |
| **SemanticRouter** | `lm_client.py`, `UserProfile` | –£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è |
| **ContextPrimer** ‚≠ê | `SemanticRouter`, `Memory` | Semantic Prefetch –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ |
| **PyBox** | `tools.py` | –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π Python |
| **ErrorMemory** | `CorrectionDetector`, `FeedbackMiner` | –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –æ—à–∏–±–æ–∫ |
| **ConfidenceScorer** | `MetricsEngine` | –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ |
| **SelfReflection** | `AdaptivePromptBuilder`, `MetricsEngine` | –°–∞–º–æ–∞–Ω–∞–ª–∏–∑ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è |

---

## –ß–∞—Å—Ç—å 1: –ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –º–æ–¥—É–ª–µ–π

### 1.1 UserProfile (`src/core/user_profile.py`)

**–§—É–Ω–∫—Ü–∏–∏:**

- `Mood` enum: HAPPY, NEUTRAL, FRUSTRATED, CURIOUS, BUSY
- `Verbosity` enum: BRIEF, BALANCED, DETAILED
- `Formality` enum: FORMAL, FRIENDLY, CASUAL
- `UserPreferences` dataclass: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∏–ª—è
- `UserHabits` dataclass: –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**

```python
analyze_mood(text) ‚Üí Mood          # –î–µ—Ç–µ–∫—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (–±–µ–∑ –ø–æ–±–æ—á–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤)
detect_mood(text) ‚Üí Mood           # + —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
get_style_prompt() ‚Üí str           # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
track_interaction(message)         # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–∏–≤—ã—á–µ–∫
get_suggestions(context) ‚Üí list    # –ú—è–≥–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
get_profile_completeness() ‚Üí float # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è Empathy
get_habits_richness() ‚Üí float      # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è Empathy
```

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:** `user_profile` (singleton id=1)

```sql
name TEXT, preferences JSON, habits JSON, dislikes JSON
```

---

### 1.2 Adaptation Engine (`src/core/adaptation.py`)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

#### CorrectionDetector

```python
CORRECTION_PATTERNS = [
    (r"–Ω–µ—Ç,?\s*(—è\s+)?(–∏–º–µ–ª|–∏–º–µ–ª–∞)\s+–≤\s+–≤–∏–¥—É", "misunderstanding"),
    (r"–Ω–µ —Ç–∞–∫,?\s*(—è\s+)?(—Ö–æ—Ç–µ–ª|—Ö–æ—Ç–µ–ª–∞)", "content"),
    (r"—Å–ª–∏—à–∫–æ–º\s+(–¥–ª–∏–Ω–Ω–æ|–∫–æ—Ä–æ—Ç–∫–æ|—Å–ª–æ–∂–Ω–æ)", "style"),
    # ... 40+ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ RU/EN
]

detect(text) ‚Üí (is_correction: bool, category: str)
record_correction(orig_id, corr_id, orig_response, user_correction)
get_recent_corrections(limit) ‚Üí list[CorrectionEntry]
```

#### FeedbackMiner

```python
record_success_pattern(message_id, response_summary, category)
get_success_patterns(category, limit) ‚Üí list[SuccessPattern]
increment_pattern_usage(pattern_id)
```

#### FactEffectivenessTracker

```python
record_fact_usage(fact_id, was_positive)
get_effective_fact_ids(limit) ‚Üí list[int]
get_fact_score(fact_id) ‚Üí float
```

#### AdaptivePromptBuilder

```python
build_adaptive_prompt(base_style, include_corrections, include_successes) ‚Üí str
# –°–æ–±–∏—Ä–∞–µ—Ç: base_style + corrections + success_patterns + stats
```

#### AnticipationEngine

```python
SEQUENCES = {
    "–Ω–∞–ø–∏—Å–∞–ª –∫–æ–¥": ["–∑–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç", "–ø—Ä–æ–≤–µ—Ä—å –æ—à–∏–±–∫–∏"],
    "git": ["commit", "push", "—Å—Ç–∞—Ç—É—Å"],
    # ...
}
get_suggestions(context, user_habits) ‚Üí list[str]
```

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:**

- `correction_log`: original_response, user_correction, extracted_pattern, category
- `success_patterns`: response_summary, extracted_pattern, category
- `fact_effectiveness`: times_used, positive_outcomes, negative_outcomes

---

### 1.3 Metrics Engine (`src/core/metrics.py`)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

#### ImplicitFeedbackAnalyzer

```python
POSITIVE_SIGNALS = ["—Å–ø–∞—Å–∏–±–æ", "–æ—Ç–ª–∏—á–Ω–æ", "–∫–ª–∞—Å—Å", "thanks", "great", ...]  # 50+
NEGATIVE_SIGNALS = ["–Ω–µ—Ç", "–Ω–µ —Ç–æ", "–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ", "wrong", ...]  # 50+
CORRECTION_SIGNALS = ["–Ω–µ—Ç, —è –∏–º–µ–ª –≤ –≤–∏–¥—É", "—Ç—ã –Ω–µ –ø–æ–Ω—è–ª", ...]  # 30+

analyze(text) ‚Üí (is_positive, is_negative, is_correction)
_analyze_caps(text, already_negative) ‚Üí "frustration" | "emphasis" | "none"
```

#### MetricsEngine

**IQ Score (40% + 30% + 20% + 10%):**

```python
IQ_WEIGHTS = {
    "accuracy": 0.40,      # positive / (positive + negative)
    "correction": 0.30,    # 1 - corrections / total
    "first_try": 0.20,     # neutral_or_positive / total
    "context": 0.10        # facts_used / facts_available
}
```

**Empathy Score (40% + 25% + 20% + 15%):**

```python
EMPATHY_WEIGHTS = {
    "habit_match": 0.40,   # profile_completeness + habit_richness
    "mood": 0.25,          # fewer negatives = better
    "anticipation": 0.20,  # positive_rate as proxy
    "friction": 0.15       # trend in correction_rate
}
```

**–ú–µ—Ç–æ–¥—ã:**

```python
analyze_message(text) ‚Üí (positive, negative, correction)
record_interaction_outcome(message_id, user_message, ...)
calculate_iq() ‚Üí MetricResult
calculate_empathy() ‚Üí MetricResult
get_achievements() ‚Üí list[Achievement]
get_adaptation_proof() ‚Üí AdaptationProof  # Day 1 vs Day 30
```

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:**

- `interaction_outcomes`: was_correction, implicit_positive/negative, facts_in_context, ...
- `daily_metrics`: iq_score, empathy_score, breakdown_json
- `achievements`: threshold_type, threshold_value, current_value, unlocked_at

---

### 1.4 Memory System (`src/core/memory.py`)

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Memory Tiers                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Session Memory  ‚îÇ Recent messages (70% token budget)‚îÇ
‚îÇ  2. Summary Memory  ‚îÇ Auto-compressed older messages    ‚îÇ
‚îÇ  3. Facts Database  ‚îÇ Extracted facts + embeddings      ‚îÇ
‚îÇ  4. Cross-Session   ‚îÇ Semantic search across history    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**

```python
get_smart_context(conv_id, max_tokens, include_facts) ‚Üí list[dict]
# 1. Summary (20% tokens)
# 2. Recent messages (70% tokens)
# 3. Relevant facts (10% tokens)

compress_history(conv_id) ‚Üí str  # LLM summarization
_extract_facts(message_id, content)  # LLM extraction ‚Üí memory_facts
get_relevant_facts(conv_id, limit) ‚Üí list[Fact]  # Semantic search
```

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:**

- `messages`: role, content, tokens_used, model_used
- `memory_facts`: content, category, embedding (BLOB), confidence
- `conversation_summaries`: summary, messages_covered

---

### 1.5 LM Client (`src/core/lm_client.py`)

**–¢–µ–∫—É—â–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è (–ü–†–û–ë–õ–ï–ú–ê):**

```python
def detect_task_type(message, has_image) ‚Üí TaskType:
    if has_image: return VISION

    reasoning_keywords = ["–ø–æ—á–µ–º—É", "–æ–±—ä—è—Å–Ω–∏", "why", "explain", ...]
    quick_keywords = ["–¥–∞ –∏–ª–∏ –Ω–µ—Ç", "–∫—Ä–∞—Ç–∫–æ", "yes or no", ...]

    if any(kw in message_lower for kw in quick_keywords):
        return QUICK
    if any(kw in message_lower for kw in reasoning_keywords):
        return REASONING
    if len(message) > 200:
        return REASONING
    return DEFAULT
```

**–ü—Ä–æ–±–ª–µ–º–∞:** Keyword-based, –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É.

**Thinking Modes:**

```python
class ThinkingMode(Enum):
    FAST = "fast"       # Quick, minimal reasoning
    STANDARD = "standard"
    DEEP = "deep"       # Chain-of-thought
    VISION = "vision"   # Auto for images
```

---

### 1.6 AutoGPT Agent (`src/core/autogpt.py`)

**–¶–∏–∫–ª:**

```
set_goal(goal) ‚Üí AutoGPTRun
    ‚îÇ
    ‚ñº
_create_plan() ‚Üí list[Task]  # LLM decomposition
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  while not done and not limit: ‚îÇ
‚îÇ    _execute_next_step()        ‚îÇ
‚îÇ      ‚îÇ                         ‚îÇ
‚îÇ      ‚îú‚îÄ LLM: "what next?"     ‚îÇ
‚îÇ      ‚îú‚îÄ Check DANGEROUS_TOOLS ‚îÇ
‚îÇ      ‚îú‚îÄ tools.execute(action)  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ –ü–†–û–ë–õ–ï–ú–ê: –Ω–µ—Ç –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
‚îÇ      ‚îî‚îÄ _mark_task_progress()  ‚îÇ
‚îÇ                                ‚îÇ
‚îÇ    _check_goal_completed()     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ –ü–†–û–ë–õ–ï–ú–ê: naive check
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ü—Ä–æ–±–ª–µ–º—ã:**

1. Task —Å—á–∏—Ç–∞–µ—Ç—Å—è Done –ø—Ä–æ—Å—Ç–æ –ø–æ —Ñ–∞–∫—Ç—É –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
2. –ù–µ—Ç –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
3. –ù–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ —Å MetricsEngine

---

### 1.7 API Integration (`src/api/api.py`)

**–¢–µ–∫—É—â–∏–π flow POST /api/chat:**

```python
1. memory.add_message(conv_id, "user", message)
2. user_profile.track_interaction(message)        # Background
3. memory.get_smart_context(conv_id)
4. rag.get_context_for_query(message)             # Optional
5. prompt_builder.build_adaptive_prompt(message)  # Personalization
6. lm_client.chat(..., thinking_mode=..., stream=True)
7. memory.add_message(conv_id, "assistant", response)
```

**‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –£–ü–£–©–ï–ù–ò–ï:**

```python
# –û–¢–°–£–¢–°–¢–í–£–ï–¢ –≤ —Ç–µ–∫—É—â–µ–º –∫–æ–¥–µ:
await metrics_engine.record_interaction_outcome(...)
```

–ú–µ—Ç—Ä–∏–∫–∏ IQ/Empathy –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è, –Ω–æ –Ω–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è!

---

## –ß–∞—Å—Ç—å 2: –ù–æ–≤—ã–µ –º–æ–¥—É–ª–∏ –∏ –∏—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### 2.1 SafeShell (P0 - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)

**–§–∞–π–ª:** `src/core/safe_shell.py`

**–ü—Ä–æ–±–ª–µ–º–∞ –≤ `tools.py:run_command`:**

```python
# –¢–µ–∫—É—â–∏–π –∫–æ–¥:
proc = await asyncio.create_subprocess_exec("dir")  # ‚ùå Windows: FileNotFoundError
```

**–†–µ—à–µ–Ω–∏–µ:**

```python
# src/core/safe_shell.py

WINDOWS_BUILTINS = {
    "dir", "echo", "type", "copy", "move", "del", "rd", "md",
    "ren", "cls", "date", "time", "ver", "vol", "path", "set",
    "cd", "pushd", "popd", "mkdir", "rmdir", "erase"
}

@dataclass
class ShellResult:
    stdout: str
    stderr: str
    return_code: int
    timed_out: bool = False

class SafeShell:
    """Cross-platform shell with Windows built-in support."""

    def _needs_shell_wrap(self, command: str) -> bool:
        """Check if command needs cmd /c wrapper."""
        if not self.is_windows:
            return False
        base_cmd = command.strip().split()[0].lower()
        return base_cmd in WINDOWS_BUILTINS

    def _prepare_command(self, command: str) -> tuple[str, ...]:
        if self._needs_shell_wrap(command):
            return ("cmd", "/c", command)
        return tuple(shlex.split(command))

    async def execute(
        self,
        command: str,
        cwd: Optional[str] = None,
        timeout: float = 60.0,
        on_stdout: Optional[callable] = None  # Real-time streaming
    ) -> ShellResult:
        args = self._prepare_command(command)
        proc = await asyncio.create_subprocess_exec(
            *args,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=cwd
        )
        # ... streaming + timeout handling ...
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ `tools.py`:**

```python
from .safe_shell import safe_shell

async def _tool_run_command(self, command: str, cwd: str = ".") -> ToolResult:
    # Security checks...
    result = await safe_shell.execute(command, cwd=cwd, timeout=60.0)
    return ToolResult(
        success=result.return_code == 0,
        output=result.stdout + ("\n[stderr]: " + result.stderr if result.stderr else "")
    )
```

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Low | **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** –ù–µ—Ç | **–¢–µ—Å—Ç—ã:** `test_safe_shell.py`

---

### 2.2 SemanticRouter (P1 - –í—ã—Å–æ–∫–∏–π)

**–§–∞–π–ª:** `src/core/semantic_router.py`

**–ó–∞–º–µ–Ω—è–µ—Ç:** `lm_client.detect_task_type()` (keyword-based)

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SemanticRouter                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                            ‚îÇ
‚îÇ  Intent Probes (pre-computed embeddings):                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  CODE    ‚îÇ ‚îÇ REASON   ‚îÇ ‚îÇ CREATIVE ‚îÇ ‚îÇ  MATH    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ embed[n] ‚îÇ ‚îÇ embed[n] ‚îÇ ‚îÇ embed[n] ‚îÇ ‚îÇ embed[n] ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Query:                                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ  ‚îÇ "–ü–æ—á–µ–º—É –∫–æ–¥ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"‚îÇ ‚îÄ‚îÄembed‚îÄ‚îÄ‚ñ∂ [q1, q2, ..., qn] ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Cosine Similarity:                                        ‚îÇ
‚îÇ  CODE: 0.82  ‚óÑ‚îÄ‚îÄ Winner                                    ‚îÇ
‚îÇ  REASON: 0.78                                              ‚îÇ
‚îÇ  CREATIVE: 0.31                                            ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Output: RouteDecision(category=CODE, model=deepseek-coder)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° UserProfile:**

```python
async def route(
    self,
    query: str,
    user_profile: UserProfile,  # –í–ê–ñ–ù–û: —É—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è!
    has_image: bool = False
) -> RouteDecision:
    base_decision = await self._semantic_route(query)

    # –£—á–∏—Ç—ã–≤–∞–µ–º verbosity –∏–∑ UserProfile
    if user_profile.preferences.verbosity == Verbosity.BRIEF:
        if base_decision.category not in [IntentCategory.REASONING, IntentCategory.CODE]:
            base_decision.thinking_mode = "fast"

    return base_decision
```

**Fallback:** –ï—Å–ª–∏ embedding –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `_fallback_route()` —Å keywords.

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Medium | **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** `lm_client.get_embedding()`, `UserProfile`

---

### 2.2a ContextPrimer (P1 - –í—ã—Å–æ–∫–∏–π) ‚≠ê NEW

**–§–∞–π–ª:** `src/core/context_primer.py`

**–ö–æ–Ω—Ü–µ–ø—Ü–∏—è:** Semantic Prefetch ‚Äî –ø–æ–¥—Ç—è–≥–∏–≤–∞–Ω–∏–µ –¢–û–õ–¨–ö–û —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –î–û –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ö–∞–∫ "–ø–æ–ª–æ–∂–∏—Ç—å –Ω—É–∂–Ω–æ–µ –Ω–∞ —Å—Ç–æ–ª" –ø–µ—Ä–µ–¥ —Ä–∞–±–æ—Ç–æ–π.

**–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ Best Practices 2024-2025:**

- Contextual Retrieval (Anthropic) ‚Äî -49% failure rate
- Semantic Caching ‚Äî –¥–æ 60% cache hits
- Hierarchical Memory (HiAgent) ‚Äî HOT ‚Üí WORKING ‚Üí EPISODIC

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      ContextPrimer Flow                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                           ‚îÇ
‚îÇ  ‚îÇ User Query       ‚îÇ                                           ‚îÇ
‚îÇ  ‚îÇ "—Ö–æ—á—É –ø–æ–∫–æ–¥–∏—Ç—å"  ‚îÇ                                           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                           ‚îÇ
‚îÇ           ‚îÇ                                                      ‚îÇ
‚îÇ           ‚ñº                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ 1. INTENT DETECTOR (fast, ~10ms)             ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    - Semantic similarity vs domain embeddings‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    - Fallback: keyword triggers              ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Domain: "code"                          ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ           ‚îÇ                                                      ‚îÇ
‚îÇ           ‚ñº                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ 2. SEMANTIC CACHE CHECK                      ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    Similar query cached? ‚Üí Return instantly! ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    Cache hit rate: ~40-60%                   ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ           ‚îÇ (miss)                                               ‚îÇ
‚îÇ           ‚ñº                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ 3. PARALLEL PREFETCH ("–Ω–∞ —Å—Ç–æ–ª", ~50ms)      ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ a) Domain-Specific Memories:        ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - code_patterns (–Ω–µ –≤—Å–µ!)        ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - project facts                  ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - tech preferences               ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ b) Success Patterns (domain only):  ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - code success patterns          ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - NOT creative patterns          ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ c) Tool Preparation:                ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - run_command, write_file        ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    - NOT: web_search, calendar      ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ d) Specialized Instructions:        ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ    ‚Üí code_assistant.md              ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ           ‚îÇ                                                      ‚îÇ
‚îÇ           ‚ñº                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ 4. CACHE & RETURN                            ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Store in SemanticCache for future       ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Return PrimedContext                    ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Result: ~1500 tokens (–≤–º–µ—Å—Ç–æ ~4000) = -62.5%                   ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

#### SemanticCache

```python
class SemanticCache:
    """
    Cache primed contexts by semantic similarity.
    Similar queries get the same context instantly (~0ms).
    
    ‚≠ê CACHE INVALIDATION STRATEGY:
    1. TTL-based: entries expire after ttl_seconds
    2. Manual: call clear() when memories/patterns updated
    3. Version-based: check _db_version counter on get()
    
    üöÄ OPTIMIZATION: Vectorized numpy for O(1) lookup instead of O(n) loop
    """
    
    # üöÄ OPTIMIZATION: 2000 entries = ~1GB RAM (user has 64GB)
    def __init__(self, max_size: int = 2000, ttl_seconds: int = 3600):
        self._cache: dict[str, tuple[PrimedContext, float]] = {}
        self._embeddings: dict[str, list[float]] = {}
        self._embedding_matrix: Optional[np.ndarray] = None  # üöÄ Vectorized cache
        self._max_size = max_size
        self._ttl = ttl_seconds
        self._db_version: int = 0
    
    async def get(self, query: str, query_embedding: list[float]) -> Optional[PrimedContext]:
        """Check if similar query is cached (similarity > 0.92). O(1) with numpy."""
        if not self._cache:
            return None
        
        now = time.time()
        self._evict_expired(now)  # Clean up expired entries
        
        if self._embedding_matrix is None:
            return None
        
        # üöÄ OPTIMIZATION: Vectorized cosine similarity ‚Äî O(1) instead of O(n)
        query_vec = np.array(query_embedding)
        similarities = np.dot(self._embedding_matrix, query_vec) / (
            np.linalg.norm(self._embedding_matrix, axis=1) * np.linalg.norm(query_vec)
        )
        best_idx = np.argmax(similarities)
        
        if similarities[best_idx] > 0.92:
            cached_key = list(self._cache.keys())[best_idx]
            context = self._cache[cached_key][0]
            context.from_cache = True
            return context
        
        return None
    
    def put(self, query: str, embedding: list[float], context: PrimedContext):
        """Cache a primed context for future similar queries."""
        if len(self._cache) >= self._max_size:
            oldest = min(self._cache.items(), key=lambda x: x[1][1])
            del self._cache[oldest[0]]
            del self._embeddings[oldest[0]]
        
        self._cache[query] = (context, time.time())
        self._embeddings[query] = embedding
        self._rebuild_matrix()  # Rebuild for vectorized search
    
    def _rebuild_matrix(self):
        """Rebuild embedding matrix for vectorized search."""
        if self._embeddings:
            self._embedding_matrix = np.vstack(list(self._embeddings.values()))
        else:
            self._embedding_matrix = None
    
    def clear(self):
        """Clear ALL cache entries. Called when memories/patterns change."""
        self._cache.clear()
        self._embeddings.clear()
        self._embedding_matrix = None
        self._db_version += 1
    
    def invalidate_for_category(self, category: IntentCategory):
        """Clear cache entries for specific category only."""
        to_delete = [
            q for q, (ctx, _) in self._cache.items() 
            if ctx.category == category
        ]
        for q in to_delete:
            del self._cache[q]
            del self._embeddings[q]
        self._rebuild_matrix()
```

#### Domain Configuration

```python
class Domain(Enum):
    CODE = "code"
    CREATIVE = "creative"
    VISION = "vision"
    ANALYSIS = "analysis"
    CASUAL = "casual"

DOMAINS = {
    Domain.CODE: DomainConfig(
        triggers=["–∫–æ–¥", "—Ñ—É–Ω–∫—Ü–∏", "–∫–ª–∞—Å—Å", "–±–∞–≥", "python", "js", "api"],
        memory_categories=["project", "code_style", "tech_preferences"],
        pattern_types=["code", "technical", "debugging"],
        tools=["run_command", "write_file", "read_file", "python_eval"],
        instructions="code_assistant.md",
        max_memories=7
    ),
    Domain.CREATIVE: DomainConfig(
        triggers=["–Ω–∞–ø–∏—à–∏", "–ø—Ä–∏–¥—É–º–∞–π", "–∏—Å—Ç–æ—Ä–∏—è", "—Ç–µ–∫—Å—Ç", "–ø–æ—Å—Ç"],
        memory_categories=["writing_style", "tone_preferences"],
        pattern_types=["creative", "style"],
        tools=["web_search"],
        instructions="creative_writer.md",
        max_memories=5
    ),
    # ... VISION, ANALYSIS, CASUAL
}
```

#### ContextPrimer (–æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å)

```python
class ContextPrimer:
    """
    Semantic Prefetch - fetches ONLY relevant context based on RouteDecision.
    This is the "putting on the table" mechanism.
    
    ‚ÑπÔ∏è NOTE: ContextPrimer –ù–ï –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç domain —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ!
    –û–Ω –ø–æ–ª—É—á–∞–µ—Ç RouteDecision –æ—Ç SemanticRouter –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç route.category.
    """
    
    # Mapping from IntentCategory to DomainConfig
    CATEGORY_TO_CONFIG = {
        IntentCategory.CODE: DomainConfig(...),
        IntentCategory.REASONING: DomainConfig(...),
        IntentCategory.CREATIVE: DomainConfig(...),
        IntentCategory.VISION: DomainConfig(...),
        IntentCategory.QUICK: DomainConfig(...),
    }
    
    async def prime_context(
        self,
        query: str,
        route: RouteDecision,  # ‚≠ê –ü–†–ò–ù–ò–ú–ê–ï–¢ RouteDecision, –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–∞–º!
        user_profile: UserProfile
    ) -> PrimedContext:
        start_time = time.time()
        
        # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º category –∏–∑ SemanticRouter
        config = self.CATEGORY_TO_CONFIG.get(
            route.category, 
            self.CATEGORY_TO_CONFIG[IntentCategory.REASONING]  # fallback
        )
        
        # 2. Check semantic cache
        query_embedding = await self._lm_client.get_embedding(query)
        if query_embedding:
            cached = await self._cache.get(query, query_embedding)
            if cached:
                return cached  # Instant return!
        
        # 3. Parallel prefetch ("–Ω–∞ —Å—Ç–æ–ª")
        memories, patterns, tools, instructions = await asyncio.gather(
            self._fetch_memories(config),      # Only category-relevant
            self._fetch_patterns(config),      # Only category patterns
            self._prepare_tools(config),       # Only category tools
            self._load_instructions(config)    # Specialized instructions
        )
        
        context = PrimedContext(
            category=route.category,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º IntentCategory, –Ω–µ Domain
            memories=memories,
            patterns=patterns,
            tools=tools,
            instructions=instructions,
            prime_time_ms=(time.time() - start_time) * 1000
        )
        
        # 4. Cache for similar future queries
        if query_embedding:
            self._cache.put(query, query_embedding, context)
        
        return context
    
    def invalidate_cache(self):
        """–û—á–∏—Å—Ç–∏—Ç—å cache –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ memories/patterns."""
        self._cache.clear()
```

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø (–£–¢–û–ß–ù–Å–ù–ù–´–ô –ü–û–†–Ø–î–û–ö + üöÄ OPTIMIZATIONS):**

```python
# api.py - startup
from src.core.semantic_router import semantic_router
from src.core.context_primer import context_primer
from src.core.self_reflection import self_reflection

await semantic_router.initialize(lm_client)
await context_primer.initialize(memory._db, lm_client)
await self_reflection.initialize(memory._db)

# api.py - POST /api/chat
async def chat(request: ChatRequest):
    # ‚≠ê –ü–û–†–Ø–î–û–ö –í–´–ó–û–í–û–í (–ö–†–ò–¢–ò–ß–ù–û):
    
    # 1Ô∏è‚É£ SemanticRouter FIRST - –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç category, model –ò –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç embedding
    # üöÄ OPTIMIZATION: –í–æ–∑–≤—Ä–∞—â–∞–µ–º embedding –¥–ª—è reuse!
    route, query_embedding = await semantic_router.route_with_embedding(
        request.message,
        user_profile,
        request.has_image
    )
    
    # 2Ô∏è‚É£ ContextPrimer - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç route.category –∏ REUSE embedding!
    # üöÄ OPTIMIZATION: –ù–µ –≤—ã–∑—ã–≤–∞–µ–º get_embedding –ø–æ–≤—Ç–æ—Ä–Ω–æ - —ç–∫–æ–Ω–æ–º–∏—è ~100ms
    primed = await context_primer.prime_context(
        request.message,
        route,
        user_profile,
        query_embedding  # üöÄ Reuse!
    )
    
    # 3Ô∏è‚É£ SelfReflection - –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—é
    reflection_prompt = await self_reflection.build_reflection_prompt()
    
    # 4Ô∏è‚É£ Build context
    context = []
    if reflection_prompt:
        context.append({"role": "system", "content": reflection_prompt})
    context.extend([{"role": "system", "content": m["content"]} for m in primed.memories])
    
    # 5Ô∏è‚É£ LLM call with route.model and route.thinking_mode
    response = await lm_client.chat(
        model=route.model,
        thinking_mode=ThinkingMode(route.thinking_mode),
        ...
    )
    
    # üöÄ OPTIMIZATION: –ü–æ–∫–∞–∑–∞—Ç—å prime_time –≤ UI
    done_data["prime_time_ms"] = primed.prime_time_ms
    
    # 6Ô∏è‚É£ üöÄ Background Prefetch –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–≤–æ –≤—Ä–µ–º—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞)
    asyncio.create_task(
        context_primer.warm_cache_for_likely_followup(route.category)
    )
```

**–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (üöÄ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏):**

| –ú–µ—Ç—Ä–∏–∫–∞ | –ë–µ–∑ Priming | –° Priming v3.4 | –£–ª—É—á—à–µ–Ω–∏–µ |
|---------|-------------|----------------|----------|
| –ö–æ–Ω—Ç–µ–∫—Å—Ç | ~4000 —Ç–æ–∫–µ–Ω–æ–≤ | ~1500 —Ç–æ–∫–µ–Ω–æ–≤ | **-62.5%** |
| Retrieval time | ~200ms | ~30ms (vectorized) | **-85%** |
| Cache hit | N/A | **~75%** üöÄ (2000 entries) | **–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ** |
| Embedding calls | 2/request | **1/request** üöÄ | **-50%** |
| Cache lookup | O(n) | **O(1)** üöÄ numpy | **10x faster** |

**–ë–æ–Ω—É—Å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (Low Hanging Fruits):**

1. **Contextual Chunk Prepending** (Anthropic pattern):
   - –ü—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ memories –¥–æ–±–∞–≤–ª—è—Ç—å –º–µ—Ç–∞-–∫–æ–Ω—Ç–µ–∫—Å—Ç
   - `"[code_style, Python] –ò—Å–ø–æ–ª—å–∑—É–π async"` –≤–º–µ—Å—Ç–æ `"–ò—Å–ø–æ–ª—å–∑—É–π async"`
   - –≠—Ñ—Ñ–µ–∫—Ç: +35% retrieval accuracy

2. **Hybrid Search (Embeddings + BM25)**:
   - –û–±—ä–µ–¥–∏–Ω–∏—Ç—å semantic + keyword search
   - –≠—Ñ—Ñ–µ–∫—Ç: +14% accuracy –ø–æ–≤–µ—Ä—Ö semantic only

3. **Domain-Specific Instructions Files**:

   ```text
   MIND/instructions/
   ‚îú‚îÄ‚îÄ code_assistant.md
   ‚îú‚îÄ‚îÄ creative_writer.md
   ‚îú‚îÄ‚îÄ vision_describer.md
   ‚îî‚îÄ‚îÄ default.md
   ```

4. **üÜï Conversation Context Prefetch**:

   ```python
   # –ü—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ ‚Äî prefetch —Å—Ä–∞–∑—É
   async def on_conversation_open(conv_id: int):
       last_category = await get_last_message_category(conv_id)
       await context_primer.warm_cache_for_category(last_category)
   ```

   –≠—Ñ—Ñ–µ–∫—Ç: **-100ms** –Ω–∞ –ø–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤ –¥–∏–∞–ª–æ–≥–µ

5. **üÜï Startup Warming**:

   ```python
   # –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ‚Äî –ø—Ä–æ–≥—Ä–µ–≤ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
   @app.on_event("startup")
   async def warm_caches():
       asyncio.create_task(context_primer.warm_common_categories())
   ```

   –≠—Ñ—Ñ–µ–∫—Ç: Cache ready —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞

6. **üÜï Shared Embedding Service** (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø):

   ```python
   class EmbeddingService:
       """Centralized embedding with in-memory cache. Dedup ALL embedding calls."""
       _cache: dict[str, list[float]] = {}
       
       async def get_or_compute(self, text: str) -> list[float]:
           if text in self._cache:
               return self._cache[text]
           embedding = await lm_client.get_embedding(text)
           self._cache[text] = embedding
           return embedding
   ```

   –≠—Ñ—Ñ–µ–∫—Ç: **Dedup embedding calls across ALL modules** (Router, Primer, ErrorMemory)

7. **üÜï Cognitive Health Endpoint**:

   ```python
   @app.get("/api/health/cognitive")
   async def cognitive_health():
       return {
           "cache_hit_rate": context_primer.get_cache_stats(),
           "avg_prime_time_ms": context_primer.get_avg_prime_time(),
           "routing_accuracy": semantic_router.get_accuracy(),
           "iq_today": (await metrics_engine.calculate_iq()).score
       }
   ```

   –≠—Ñ—Ñ–µ–∫—Ç: **Observability –∏–∑ –∫–æ—Ä–æ–±–∫–∏**

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Medium | **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** `SemanticRouter`, `Memory`, `lm_client.get_embedding()`

**Checklist:**

- [ ] SemanticCache —Å TTL, eviction –∏ invalidation ‚úÖ (–æ–ø–∏—Å–∞–Ω–æ)
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RouteDecision.category (–ù–ï —Å–≤–æ–π domain detection!) ‚úÖ
- [ ] Parallel prefetch –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- [ ] Integration –≤ api.py (startup + chat) ‚Äî –ø–æ—Ä—è–¥–æ–∫: Router‚ÜíPrimer‚ÜíReflection
- [ ] Category-specific instruction files
- [ ] Performance < 100ms (with cache miss)
- [ ] Fallback –µ—Å–ª–∏ embedding API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω

---

### 2.3 ReflectiveAgent (P1 - –í—ã—Å–æ–∫–∏–π)

**–§–∞–π–ª:** `src/core/agent_v2.py`

**–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê –≤ `autogpt.py`:**

```python
# –¢–µ–∫—É—â–∏–π –∫–æ–¥:
step.result = await tools.execute(action, action_input)
step.status = StepStatus.COMPLETED  # ‚ùå –ë–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞!
```

**–†–µ—à–µ–Ω–∏–µ: Verifier Pattern**

```
–¢–ï–ö–£–©–ò–ô –ü–û–¢–û–ö:                    –ù–û–í–´–ô –ü–û–¢–û–ö:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Execute     ‚îÇ                   ‚îÇ Execute     ‚îÇ
‚îÇ action      ‚îÇ                   ‚îÇ action      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                 ‚îÇ
      ‚ñº                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Mark DONE   ‚îÇ ‚ùå                ‚îÇ Verify      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ result      ‚îÇ
                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                  ‚îÇ PASS/FAIL?  ‚îÇ
                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ                         ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ Mark DONE ‚îÇ             ‚îÇ Iterate   ‚îÇ
                     ‚îÇ + record  ‚îÇ             ‚îÇ with      ‚îÇ
                     ‚îÇ metrics   ‚îÇ             ‚îÇ critique  ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° MetricsEngine:**

```python
class ReflectiveAgent(AutoGPTAgent):
    """Extends AutoGPTAgent with verification."""

    async def _execute_next_step(self) -> Optional[Step]:
        step = await super()._execute_next_step()

        if step and step.status == StepStatus.COMPLETED:
            verification = await self._verify_step(step)

            # –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø: –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ MetricsEngine!
            await metrics_engine.record_interaction_outcome(
                was_correction=(verification.status == VerificationResult.FAIL),
                # verification confidence –≤–ª–∏—è–µ—Ç –Ω–∞ IQ
            )

            if verification.status == VerificationResult.FAIL:
                # Retry logic...

        return step
```

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Medium | **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** `autogpt.py`, `MetricsEngine`

---

### 2.4 ErrorMemory (P2 - –°—Ä–µ–¥–Ω–∏–π)

**–§–∞–π–ª:** `src/core/error_memory.py`

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º `CorrectionDetector`:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Error Learning Flow                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  –°–£–©–ï–°–¢–í–£–Æ–©–ï–ï:                                                ‚îÇ
‚îÇ  CorrectionDetector.detect("–Ω–µ—Ç, —è –∏–º–µ–ª –≤ –≤–∏–¥—É X")            ‚îÇ
‚îÇ       ‚îÇ                                                       ‚îÇ
‚îÇ       ‚ñº                                                       ‚îÇ
‚îÇ  correction_log table (regex patterns)                        ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  –ù–û–í–û–ï (ErrorMemory):                                         ‚îÇ
‚îÇ  CorrectionDetector.detect(...)                               ‚îÇ
‚îÇ       ‚îÇ                                                       ‚îÇ
‚îÇ       ‚ñº                                                       ‚îÇ
‚îÇ  ErrorMemory.record_error_correction(                         ‚îÇ
‚îÇ      error_pattern,                                           ‚îÇ
‚îÇ      wrong_action,                                            ‚îÇ
‚îÇ      correct_action,                                          ‚îÇ
‚îÇ      embedding  ‚óÑ‚îÄ‚îÄ‚îÄ –î–û–ë–ê–í–õ–Ø–ï–ú –í–ï–ö–¢–û–† –¥–ª—è similarity search   ‚îÇ
‚îÇ  )                                                            ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:                                               ‚îÇ
‚îÇ  Before action ‚Üí ErrorMemory.recall_similar_errors(context)   ‚îÇ
‚îÇ       ‚îÇ                                                       ‚îÇ
‚îÇ       ‚ñº                                                       ‚îÇ
‚îÇ  "‚ö†Ô∏è –í –ø—Ä–æ—à–ª–æ–º 'del' –Ω–µ —Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–π Remove-Item"       ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ö–æ–¥ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:**

```python
class ErrorMemory:
    """Vector-based error memory, EXTENDS CorrectionDetector."""

    def __init__(self, correction_detector: CorrectionDetector, db: aiosqlite.Connection):
        self._correction_detector = correction_detector  # –ù–ï –ó–ê–ú–ï–ù–Ø–ï–ú, —Ä–∞—Å—à–∏—Ä—è–µ–º!
        self._db = db

    async def record_from_user_correction(
        self,
        user_message: str,
        assistant_previous_response: str
    ):
        """Called when user corrects assistant."""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –°–£–©–ï–°–¢–í–£–Æ–©–ò–ô CorrectionDetector
        is_correction, category = self._correction_detector.detect(user_message)

        if not is_correction:
            return

        # –î–æ–±–∞–≤–ª—è–µ–º embedding –¥–ª—è vector search
        embedding = await lm_client.get_embedding(
            f"{category} {assistant_previous_response[:200]}"
        )

        await self._db.execute("""
            INSERT INTO error_memory
            (error_pattern, wrong_action, correct_action, context, embedding)
            VALUES (?, ?, ?, ?, ?)
        """, (category, assistant_previous_response[:500], user_message[:500],
              category, embedding))  # ‚úÖ FIX: –±—ã–ª–æ embedding_blob, —Å—Ç–∞–ª–æ embedding
```

**–ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞:**

```sql
CREATE TABLE IF NOT EXISTS error_memory (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    error_pattern TEXT NOT NULL,
    wrong_action TEXT NOT NULL,
    correct_action TEXT NOT NULL,
    context TEXT,
    embedding BLOB,              -- Vector for similarity search
    occurrences INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_used TIMESTAMP
);

-- üöÄ OPTIMIZATION: Index –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è vector scan –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 30 –¥–Ω—è–º–∏
CREATE INDEX IF NOT EXISTS idx_error_memory_created ON error_memory(created_at DESC);
```

**üöÄ OPTIMIZATION: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ vector scan:**

```python
async def recall_similar_errors(self, context_embedding: list[float], limit: int = 5):
    """Find similar past errors. LIMITED to last 30 days to avoid O(n) on large tables."""
    # üöÄ Limit scan to recent entries only
    async with self._db.execute("""
        SELECT embedding, error_pattern, correct_action 
        FROM error_memory 
        WHERE created_at > datetime('now', '-30 days')
        ORDER BY created_at DESC
        LIMIT 100  -- Max entries to compare
    """) as cursor:
        rows = await cursor.fetchall()
    
    # Vectorized similarity search on limited set
    if not rows:
        return []
    
    embeddings = np.vstack([pickle.loads(r[0]) for r in rows])
    similarities = np.dot(embeddings, context_embedding) / (
        np.linalg.norm(embeddings, axis=1) * np.linalg.norm(context_embedding)
    )
    
    top_indices = np.argsort(similarities)[-limit:][::-1]
    return [rows[i] for i in top_indices if similarities[i] > 0.7]
```

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Medium | **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** `CorrectionDetector` | **–ù–ï –õ–û–ú–ê–ï–¢ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ**

---

### 2.5 PyBox Sandbox (P2 - –°—Ä–µ–¥–Ω–∏–π)

**–§–∞–π–ª:** `src/core/pybox.py`

**–ó–∞—á–µ–º:**

- LLM –ø–ª–æ—Ö–æ —Å—á–∏—Ç–∞–µ—Ç: `1234567 * 7654321 = ?`
- Data analysis: pandas, statistics
- Validation: regex, formats

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PyBox Security Layers                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                            ‚îÇ
‚îÇ  1. AST Analysis (static)                                  ‚îÇ
‚îÇ     ‚îú‚îÄ BLOCKED_IMPORTS: os, sys, subprocess, socket, ...  ‚îÇ
‚îÇ     ‚îú‚îÄ BLOCKED_CALLS: exec, eval, open, __import__, ...   ‚îÇ
‚îÇ     ‚îî‚îÄ ALLOWED_IMPORTS: math, json, datetime, numpy, ...  ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  2. Runtime Restrictions                                   ‚îÇ
‚îÇ     ‚îú‚îÄ Timeout: 10 seconds                                ‚îÇ
‚îÇ     ‚îú‚îÄ Output limit: 100KB                                ‚îÇ
‚îÇ     ‚îú‚îÄ No network access                                  ‚îÇ
‚îÇ     ‚îî‚îÄ No filesystem access                               ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  3. Execution in isolated temp file                        ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–∞–∫ tool:**

```python
TOOLS.append({
    "name": "python_eval",
    "description": "Execute Python code for calculations (math, data analysis)",
    "parameters": {
        "code": {"type": "string", "description": "Python code to execute"}
    }
})

async def _tool_python_eval(self, code: str) -> ToolResult:
    result = await pybox.execute(code)
    return ToolResult(result.success, result.output, result.error)
```

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** High | **–¢–µ—Å—Ç—ã:** –ö–†–ò–¢–ò–ß–ï–°–ö–ò –≤–∞–∂–Ω—ã –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

---

### 2.6 ConfidenceScorer (P3 - Low)

**–§–∞–π–ª:** `src/core/confidence.py`

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø —Å `MetricsEngine`:**

```python
# –ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –≤ api.py:
confidence = confidence_scorer.score_response(full_response, route.category.value)

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ MetricsEngine
await metrics_engine.record_interaction_outcome(
    message_id=saved_msg.id,
    user_message=request.message,
    confidence_score=confidence.score  # –ù–û–í–û–ï –ü–û–õ–ï
)

# UI –º–æ–∂–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å confidence badge
done_data["confidence"] = confidence.score
```

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Low | **–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ**

---

### 2.7 SelfReflection (P1 - –í—ã—Å–æ–∫–∏–π) ‚≠ê NEW

**–§–∞–π–ª:** `src/core/self_reflection.py`

**–§–∏–ª–æ—Å–æ—Ñ–∏—è:**

LLM –Ω–µ –∏–º–µ–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —Å–æ–∑–Ω–∞–Ω–∏—è ‚Äî –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å —ç—Ç–æ "—á–∏—Å—Ç—ã–π –ª–∏—Å—Ç".
–ù–æ –º—ã –º–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å **–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—É—é –∏–ª–ª—é–∑–∏—é —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è**,
–ø–æ–∫–∞–∑—ã–≤–∞—è –º–æ–¥–µ–ª–∏ –µ—ë —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SelfReflection Flow                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                           ‚îÇ
‚îÇ  ‚îÇ  MetricsEngine  ‚îÇ                                           ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ IQ 7 –¥–Ω–µ–π   ‚îÇ                                           ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ IQ —Å–µ–≥–æ–¥–Ω—è  ‚îÇ                                           ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ —Ç—Ä–µ–Ω–¥       ‚îÇ                                           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                           ‚îÇ
‚îÇ           ‚îÇ                                                     ‚îÇ
‚îÇ           ‚ñº                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ  ‚îÇ CorrectionLog   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ SelfReflection  ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 3)   ‚îÇ     ‚îÇ    Builder      ‚îÇ                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                                   ‚îÇ                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ                             ‚îÇ
‚îÇ  ‚îÇ SuccessPatterns ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                             ‚îÇ
‚îÇ  ‚îÇ (—Ç–æ–ø-2)         ‚îÇ              ‚îÇ                             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚ñº                             ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ                          ‚îÇ Reflection      ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ Prompt          ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ                 ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ "–¢–≤–æ–π IQ: 78‚Üí85 ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ  –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π:   ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ  - –æ—à–∏–±–∫—É X     ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ  - –æ—à–∏–±–∫—É Y     ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ  –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:  ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ  - –ø–∞—Ç—Ç–µ—Ä–Ω A"   ‚îÇ                   ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                                   ‚îÇ                             ‚îÇ
‚îÇ                                   ‚ñº                             ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ                          ‚îÇ Context –¥–ª—è LLM ‚îÇ                   ‚îÇ
‚îÇ                          ‚îÇ (system prompt) ‚îÇ                   ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ü–æ—á–µ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. **LLM —Å–ª–µ–¥—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º** ‚Äî –≤–∏–¥—è "–Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ—à–∏–±–∫—É X", –º–æ–¥–µ–ª—å —É—á–∏—Ç—ã–≤–∞–µ—Ç —ç—Ç–æ
2. **–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã** –ª—É—á—à–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
3. **–ß–∏—Å–ª–∞ —Å–æ–∑–¥–∞—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç** ‚Äî "IQ 78‚Üí85" —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ—â—É—â–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
4. **–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∫–æ—Ä—å** ‚Äî –º–æ–¥–µ–ª—å "—Ö–æ—á–µ—Ç" —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ö–æ—Ä–æ—à–∏–π —Ç—Ä–µ–Ω–¥

**‚ö†Ô∏è –í–ê–ñ–ù–û: –û—Ç–ª–∏—á–∏–µ –æ—Ç AdaptivePromptBuilder**

```
AdaptivePromptBuilder:              SelfReflection:
‚îú‚îÄ –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã                   ‚îú‚îÄ –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
‚îú‚îÄ "–ë—É–¥—å –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–µ–µ"              ‚îú‚îÄ "IQ –±—ã–ª 72, —Å—Ç–∞–ª 85 (+13)"
‚îú‚îÄ –ë–µ–∑ —á–∏—Å–µ–ª                        ‚îú‚îÄ –° —á–∏—Å–ª–∞–º–∏ –∏ —Ç—Ä–µ–Ω–¥–∞–º–∏
‚îî‚îÄ –î–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤                ‚îî‚îÄ –î–ª—è "–æ—Å–æ–∑–Ω–∞–Ω–Ω–æ—Å—Ç–∏" –º–æ–¥–µ–ª–∏
```

**SelfReflection –î–û–ü–û–õ–ù–Ø–ï–¢ AdaptivePromptBuilder, –Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç.**

**–ö–æ–¥:**

```python
# src/core/self_reflection.py

from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional
import aiosqlite

from .metrics import metrics_engine
from .adaptation import correction_detector, feedback_miner


@dataclass
class ReflectionData:
    """Data for self-reflection prompt."""
    iq_week_ago: float
    iq_today: float
    iq_trend: str  # "‚Üë", "‚Üì", "‚Üí"
    empathy_week_ago: float
    empathy_today: float
    recent_mistakes: list[str]  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    what_works: list[str]  # –£—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    streak_days: int  # –î–Ω–µ–π –±–µ–∑ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤


class SelfReflectionBuilder:
    """
    Builds self-reflection prompts that show the model its own progress.

    Creates an architectural illusion of continuous self-improvement
    by injecting statistics and specific examples into context.
    """

    def __init__(self, db: Optional[aiosqlite.Connection] = None):
        self._db = db

    async def initialize(self, db: aiosqlite.Connection):
        self._db = db

    async def build_reflection_prompt(self, include_motivation: bool = True) -> str:
        """
        Build a self-reflection prompt with statistics and examples.

        Args:
            include_motivation: Add motivational framing

        Returns:
            System prompt showing model its progress
        """
        data = await self._gather_reflection_data()

        parts = []

        # 1. Statistics header
        parts.append(self._build_stats_section(data))

        # 2. Specific mistakes to avoid
        if data.recent_mistakes:
            parts.append(self._build_mistakes_section(data.recent_mistakes))

        # 3. What works well
        if data.what_works:
            parts.append(self._build_success_section(data.what_works))

        # 4. Motivational framing (optional)
        if include_motivation:
            parts.append(self._build_motivation_section(data))

        return "\n\n".join(parts)

    def _build_stats_section(self, data: ReflectionData) -> str:
        """Build statistics section."""
        iq_diff = data.iq_today - data.iq_week_ago
        empathy_diff = data.empathy_today - data.empathy_week_ago

        iq_sign = "+" if iq_diff > 0 else ""
        empathy_sign = "+" if empathy_diff > 0 else ""

        return f"""[üìä –¢–≤–æ—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞]
IQ: {data.iq_week_ago:.0f} ‚Üí {data.iq_today:.0f} ({iq_sign}{iq_diff:.0f}) {data.iq_trend}
Empathy: {data.empathy_week_ago:.0f} ‚Üí {data.empathy_today:.0f} ({empathy_sign}{empathy_diff:.0f})
Streak: {data.streak_days} –¥–Ω–µ–π –±–µ–∑ –Ω–µ–≥–∞—Ç–∏–≤–∞"""

    def _build_mistakes_section(self, mistakes: list[str]) -> str:
        """Build mistakes to avoid section."""
        items = "\n".join(f"  ‚ùå {m}" for m in mistakes[:3])
        return f"""[‚ö†Ô∏è –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —ç—Ç–∏ –æ—à–∏–±–∫–∏]
{items}"""

    def _build_success_section(self, successes: list[str]) -> str:
        """Build what works section."""
        items = "\n".join(f"  ‚úì {s}" for s in successes[:2])
        return f"""[‚úÖ –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ]
{items}"""

    def _build_motivation_section(self, data: ReflectionData) -> str:
        """Build motivational framing."""
        if data.iq_today > data.iq_week_ago:
            return "üìà –¢–≤–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–º–µ—Ç–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!"
        elif data.streak_days >= 3:
            return f"üî• {data.streak_days} –¥–Ω–µ–π –æ—Ç–ª–∏—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã! –ù–µ —Å–±–∞–≤–ª—è–π."
        elif data.iq_today < data.iq_week_ago:
            return "üí™ –ù–µ–±–æ–ª—å—à–æ–π —Å–ø–∞–¥ ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏."
        else:
            return "üéØ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞. –ï—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–æ—Å—Ç–∞!"

    async def _gather_reflection_data(self) -> ReflectionData:
        """Gather all data for reflection."""
        # üöÄ OPTIMIZATION: asyncio.gather –≤–º–µ—Å—Ç–æ sequential awaits (-80% latency)
        (
            iq_today,
            iq_week_ago,
            empathy_today,
            empathy_week_ago,
            corrections,
            patterns,
            streak
        ) = await asyncio.gather(
            metrics_engine.calculate_iq(),
            self._get_metric_for_date("iq", days_ago=7),
            metrics_engine.calculate_empathy(),
            self._get_metric_for_date("empathy", days_ago=7),
            correction_detector.get_recent_corrections(limit=3),
            feedback_miner.get_success_patterns(limit=2),
            self._calculate_positive_streak()
        )

        # Determine trend
        iq_diff = iq_today.score - iq_week_ago
        if iq_diff > 5:
            trend = "‚Üë"
        elif iq_diff < -5:
            trend = "‚Üì"
        else:
            trend = "‚Üí"

        # Process mistakes
        mistakes = []
        for c in corrections:
            if c.category == "misunderstanding":
                mistakes.append(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω—è–ª –∑–∞–ø—Ä–æ—Å: '{c.correction[:50]}...'")
            elif c.category == "style":
                mistakes.append(f"–°—Ç–∏–ª—å –Ω–µ –ø–æ–¥–æ—à—ë–ª: {c.pattern}")
            elif c.category == "content":
                mistakes.append(f"–û—Ç–≤–µ—Ç–∏–ª –Ω–µ –Ω–∞ —Ç–æ—Ç –≤–æ–ø—Ä–æ—Å")

        what_works = [p.pattern for p in patterns]

        return ReflectionData(
            iq_week_ago=iq_week_ago,
            iq_today=iq_today.score,
            iq_trend=trend,
            empathy_week_ago=empathy_week_ago,
            empathy_today=empathy_today.score,
            recent_mistakes=mistakes,
            what_works=what_works,
            streak_days=streak
        )

    async def _get_metric_for_date(self, metric_type: str, days_ago: int) -> float:
        """Get historical metric value."""
        target_date = (datetime.now() - timedelta(days=days_ago)).date().isoformat()

        column = "iq_score" if metric_type == "iq" else "empathy_score"

        async with self._db.execute(f"""
            SELECT {column} FROM daily_metrics
            WHERE metric_date <= ?
            ORDER BY metric_date DESC
            LIMIT 1
        """, (target_date,)) as cursor:
            row = await cursor.fetchone()

        return row[0] if row and row[0] else 50.0  # Default baseline

    async def _calculate_positive_streak(self) -> int:
        """Calculate days without negative feedback."""
        async with self._db.execute("""
            SELECT metric_date, negative_count
            FROM daily_metrics
            ORDER BY metric_date DESC
            LIMIT 30
        """) as cursor:
            rows = await cursor.fetchall()

        streak = 0
        for row in rows:
            if row[1] == 0:  # No negatives
                streak += 1
            else:
                break

        return streak


# Global instance
self_reflection = SelfReflectionBuilder()


async def initialize_self_reflection(db: aiosqlite.Connection):
    """Initialize self-reflection with database."""
    await self_reflection.initialize(db)
```

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –≤ `api.py`:**

```python
from src.core.self_reflection import self_reflection, initialize_self_reflection

@app.on_event("startup")
async def startup():
    # ... existing ...
    await initialize_self_reflection(memory._db)  # NEW

@app.post("/api/chat")
async def chat(request: ChatRequest):
    # ... existing context building ...

    # NEW: Self-reflection prompt (–ø–µ—Ä–µ–¥ adaptive prompt)
    reflection_prompt = await self_reflection.build_reflection_prompt()
    context.insert(0, {"role": "system", "content": reflection_prompt})

    # Existing: Adaptive prompt
    style_prompt = await prompt_builder.build_adaptive_prompt(request.message)
    # ...
```

**‚ö†Ô∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø —Å `AdaptivePromptBuilder`:**

–ú–æ–∂–Ω–æ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –æ–¥–∏–Ω –≤—ã–∑–æ–≤:

```python
# –í adaptation.py –¥–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥:

class AdaptivePromptBuilder:
    async def build_full_prompt(
        self,
        base_style_prompt: str = "",
        include_reflection: bool = True,  # NEW
        include_corrections: bool = True,
        include_successes: bool = True
    ) -> str:
        parts = []

        # NEW: Self-reflection first (sets context)
        if include_reflection:
            from .self_reflection import self_reflection
            reflection = await self_reflection.build_reflection_prompt(
                include_motivation=True
            )
            parts.append(reflection)

        # Existing adaptive prompt logic...
        # ...

        return "\n\n".join(parts)
```

**–ü—Ä–∏–º–µ—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞:**

```
[üìä –¢–≤–æ—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞]
IQ: 72 ‚Üí 85 (+13) ‚Üë
Empathy: 68 ‚Üí 74 (+6)
Streak: 5 –¥–Ω–µ–π –±–µ–∑ –Ω–µ–≥–∞—Ç–∏–≤–∞

[‚ö†Ô∏è –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —ç—Ç–∏ –æ—à–∏–±–∫–∏]
  ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω—è–ª –∑–∞–ø—Ä–æ—Å: '—è –∏–º–µ–ª –≤ –≤–∏–¥—É –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª...'
  ‚ùå –°—Ç–∏–ª—å –Ω–µ –ø–æ–¥–æ—à—ë–ª: –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞
  ‚ùå –û—Ç–≤–µ—Ç–∏–ª –Ω–µ –Ω–∞ —Ç–æ—Ç –≤–æ–ø—Ä–æ—Å

[‚úÖ –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ]
  ‚úì –£—Å–ø–µ—à–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –∫—Ä–∞—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã —Å –∫–æ–¥–æ–º
  ‚úì –£—Å–ø–µ—à–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –ø–µ—Ä–µ—Å–ø—Ä–∞—à–∏–≤–∞—Ç—å –ø—Ä–∏ –Ω–µ—è—Å–Ω–æ—Å—Ç–∏

üìà –¢–≤–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–º–µ—Ç–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!
```

**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Medium | **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** `MetricsEngine`, `AdaptivePromptBuilder`

**Checklist:**

- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MetricsEngine –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è IQ/Empathy
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CorrectionDetector –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫
- [ ] Fallback –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ –¥–Ω–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
- [ ] –ù–µ –¥—É–±–ª–∏—Ä—É–µ—Ç AdaptivePromptBuilder (–¥–æ–ø–æ–ª–Ω—è–µ—Ç)
- [ ] –ú–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- [ ] Performance < 50ms (cached metrics)

---

## –ß–∞—Å—Ç—å 3: –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ (‚ö†Ô∏è –û–°–¢–û–†–û–ñ–ù–û)

### 3.1 –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ `api.py` (POST /api/chat)

**‚ö†Ô∏è –≠–¢–û –°–ê–ú–û–ï –í–ê–ñ–ù–û–ï –ú–ï–°–¢–û –ò–ù–¢–ï–ì–†–ê–¶–ò–ò**

```python
# –¢–ï–ö–£–©–ò–ô –ö–û–î (—Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏):

@app.post("/api/chat")
async def chat(request: ChatRequest):
    # ... context building ...

    thinking_mode = ThinkingMode(request.thinking_mode)  # ‚Üê –ó–ê–ú–ï–ù–Ø–ï–ú

    # ... streaming ...

    # –û–¢–°–£–¢–°–¢–í–£–ï–¢: metrics_engine.record_interaction_outcome()


# –ù–û–í–´–ô –ö–û–î (—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π):

from src.core.semantic_router import semantic_router
from src.core.error_memory import error_memory
from src.core.confidence import confidence_scorer

@app.on_event("startup")
async def startup():
    # ... existing ...
    await semantic_router.initialize()  # NEW: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embeddings
    await error_memory.initialize(memory._db)  # NEW

@app.post("/api/chat")
async def chat(request: ChatRequest):
    # ... existing context building ...

    # NEW: Semantic routing (–∑–∞–º–µ–Ω—è–µ—Ç thinking_mode –∏–∑ request)
    route = await semantic_router.route(
        request.message,
        user_profile,  # –£—á–∏—Ç—ã–≤–∞–µ–º preferences!
        request.has_image
    )
    thinking_mode = ThinkingMode(route.thinking_mode)
    target_model = route.model

    # NEW: Error memory warning
    warning = await error_memory.get_warning_prompt(request.message)
    if warning:
        context.insert(0, {"role": "system", "content": warning})

    async def generate():
        # ... existing streaming ...

        # NEW: –ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ - confidence scoring
        confidence = confidence_scorer.score_response(full_response, route.category.value)

        # NEW: –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û!)
        await metrics_engine.record_interaction_outcome(
            message_id=saved_msg.id,
            user_message=request.message,
            facts_in_context=len(facts_used),
            style_prompt_length=len(style_prompt),
            confidence_score=confidence.score
        )

        # NEW: confidence –≤ –æ—Ç–≤–µ—Ç–µ –¥–ª—è UI
        done_data["confidence"] = confidence.score
        done_data["route"] = route.category.value
```

### 3.2 –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ `autogpt.py`

**–í–∞—Ä–∏–∞–Ω—Ç A: –ù–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**

```python
# agent_v2.py
from .autogpt import AutoGPTAgent, Step, StepStatus
from .metrics import metrics_engine

class ReflectiveAgent(AutoGPTAgent):
    """Extends AutoGPTAgent with verification."""

    async def _execute_next_step(self) -> Optional[Step]:
        # –í—ã–∑—ã–≤–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –º–µ—Ç–æ–¥
        step = await super()._execute_next_step()

        if step and step.status == StepStatus.COMPLETED:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é
            verification = await self._verify_step(step)
            step.verification = verification

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –º–µ—Ç—Ä–∏–∫–∏
            await metrics_engine.record_interaction_outcome(
                was_correction=(verification.status == VerificationResult.FAIL)
            )

            # Retry –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if verification.status == VerificationResult.FAIL:
                step = await self._retry_with_critique(step, verification)

        return step
```

**–í–∞—Ä–∏–∞–Ω—Ç B: –ó–∞–º–µ–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞**

```python
# –í api.py –ø—Ä–∏ startup:
from src.core.agent_v2 import ReflectiveAgent

_autogpt_agent = ReflectiveAgent(memory._db)  # –í–º–µ—Å—Ç–æ AutoGPTAgent
```

### 3.3 –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ `tools.py`

```python
# –î–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç
from .safe_shell import safe_shell
from .pybox import pybox

# –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π tool –≤ TOOLS list
TOOLS.append({
    "name": "python_eval",
    "description": "Execute Python code in sandbox for calculations and data analysis. "
                   "Available imports: math, statistics, datetime, json, re, numpy, pandas. "
                   "No file/network access.",
    "parameters": {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "Python code to execute"
            }
        },
        "required": ["code"]
    }
})

# –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ –≤ –∫–ª–∞—Å—Å Tools
async def _tool_python_eval(self, code: str) -> ToolResult:
    """Execute Python code in secure sandbox."""
    result = await pybox.execute(code)
    if result.success:
        return ToolResult(True, f"```\n{result.output}\n```")
    return ToolResult(False, "", result.error)

# –ò–∑–º–µ–Ω–∏—Ç—å _tool_run_command
async def _tool_run_command(self, command: str, cwd: str = ".") -> ToolResult:
    # ... existing security checks ...

    # –ó–ê–ú–ï–ù–Ø–ï–ú –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ subprocess –Ω–∞ safe_shell
    result = await safe_shell.execute(command, cwd=cwd, timeout=60.0)

    output = result.stdout
    if result.stderr:
        output += f"\n[stderr]: {result.stderr}"
    if result.timed_out:
        output += "\n[TIMED OUT]"

    return ToolResult(
        success=result.return_code == 0 and not result.timed_out,
        output=output or "(no output)"
    )
```

### 3.4 –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ `schema.sql`

```sql
-- –î–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞:

-- Error Memory (vector-based, extends correction_log)
CREATE TABLE IF NOT EXISTS error_memory (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    error_pattern TEXT NOT NULL,
    wrong_action TEXT NOT NULL,
    correct_action TEXT NOT NULL,
    context TEXT,
    embedding BLOB,              -- Vector for similarity search
    occurrences INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_used TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_error_memory_pattern ON error_memory(error_pattern);

-- Verification logs for ReflectiveAgent
CREATE TABLE IF NOT EXISTS verification_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    step_id INTEGER REFERENCES autogpt_steps(id),
    status TEXT NOT NULL CHECK (status IN ('pass', 'fail', 'partial', 'skip')),
    critique TEXT,
    suggestions TEXT,  -- JSON array
    confidence REAL,
    iteration INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_verification_step ON verification_logs(step_id);
```

---

## –ß–∞—Å—Ç—å 4: –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –§–∞–∑–∞ 1: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è (1-2 –¥–Ω—è)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 1.1 | SafeShell –¥–ª—è Windows | `safe_shell.py` | Low | –ù–µ—Ç |
| 1.2 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ tools.py | `tools.py` | Low | 1.1 |
| 1.3 | –¢–µ—Å—Ç—ã SafeShell | `test_safe_shell.py` | Low | 1.1 |
| 1.4 | **FIX: –¥–æ–±–∞–≤–∏—Ç—å record_interaction_outcome –≤ api.py** | `api.py` | Low | –ù–µ—Ç |

### –§–∞–∑–∞ 2a: –£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è + Context Priming (2-3 –¥–Ω—è)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 2a.1 | **Shared EmbeddingService** üÜï | `embedding_service.py` | Low | lm_client |
| 2a.2 | SemanticRouter –±–∞–∑–æ–≤—ã–π | `semantic_router.py` | Medium | 2a.1 |
| 2a.3 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å UserProfile | `semantic_router.py` | Low | 2a.2 |
| 2a.4 | Fallback –Ω–∞ keywords | `semantic_router.py` | Low | 2a.2 |
| 2a.5 | **ContextPrimer –º–æ–¥—É–ª—å** ‚≠ê | `context_primer.py` | Medium | 2a.1, Memory |
| 2a.6 | SemanticCache —Å numpy | `context_primer.py` | Low | 2a.5 |
| 2a.7 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Router+Primer –≤ api.py | `api.py` | Low | 2a.2, 2a.5 |
| 2a.8 | Startup Warming üÜï | `api.py` | Low | 2a.5 |

### –§–∞–∑–∞ 2b: SelfReflection + Observability (2 –¥–Ω—è)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 2b.1 | **SelfReflection –º–æ–¥—É–ª—å** | `self_reflection.py` | Medium | MetricsEngine |
| 2b.2 | asyncio.gather –¥–ª—è DB calls üöÄ | `self_reflection.py` | Low | 2b.1 |
| 2b.3 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SelfReflection –≤ api.py | `api.py` | Low | 2b.1 |
| 2b.4 | **Cognitive Health Endpoint** üÜï | `api.py` | Low | 2a.2, 2a.5 |
| 2b.5 | –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å AdaptivePromptBuilder | `adaptation.py` | Low | 2b.1 |

### –§–∞–∑–∞ 3: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ (3-4 –¥–Ω—è)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 3.1 | ReflectiveAgent –∫–ª–∞—Å—Å | `agent_v2.py` | Medium | autogpt.py |
| 3.2 | Verification prompt tuning | `agent_v2.py` | Medium | 3.1 |
| 3.3 | **Confidence-based skip** üÜï | `agent_v2.py` | Low | 3.1 |
| 3.4 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MetricsEngine | `agent_v2.py` | Low | 3.1 |
| 3.5 | UI –∏–Ω–¥–∏–∫–∞—Ü–∏—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ | Frontend | Medium | 3.1 |
| 3.6 | –¢–µ—Å—Ç—ã | `test_agent_v2.py` | Medium | 3.1 |

> **üÜï Confidence-based skip:** –ï—Å–ª–∏ `confidence > 0.9`, –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ LLM calls

### –§–∞–∑–∞ 4: –ü–∞–º—è—Ç—å –æ—à–∏–±–æ–∫ + Synergy (2-3 –¥–Ω—è)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 4.1 | ErrorMemory –∫–ª–∞—Å—Å | `error_memory.py` | Medium | CorrectionDetector |
| 4.2 | –ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ + index –≤ schema | `schema.sql` | Low | - |
| 4.3 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CorrectionDetector | `error_memory.py` | Low | 4.1 |
| 4.4 | **üîó Synergy: ErrorMemory ‚Üí ContextPrimer** üÜï | `context_primer.py` | Low | 4.1, 2a.5 |
| 4.5 | Warning injection | `api.py`, `agent_v2.py` | Low | 4.1 |

> **üîó Synergy:** ContextPrimer –º–æ–∂–µ—Ç "–≤—Å–ø–æ–º–Ω–∏—Ç—å" —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏–∑ ErrorMemory –î–û –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

### –§–∞–∑–∞ 5: Python Sandbox (3-4 –¥–Ω—è)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 5.1 | PyBox AST analyzer | `pybox.py` | High | - |
| 5.2 | Execution sandbox | `pybox.py` | High | 5.1 |
| 5.3 | Tool integration | `tools.py` | Low | 5.1 |
| 5.4 | **SECURITY TESTS** | `test_pybox.py` | Critical | 5.1 |

### –§–∞–∑–∞ 6: Confidence + Final Polish (1 –¥–µ–Ω—å)

| # | –ó–∞–¥–∞—á–∞ | –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|---|--------|------|-----------|-------------|
| 6.1 | ConfidenceScorer | `confidence.py` | Low | - |
| 6.2 | **üîó Synergy: Confidence ‚Üí SelfReflection** üÜï | `self_reflection.py` | Low | 6.1, 2b.1 |
| 6.3 | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ API | `api.py` | Low | 6.1 |
| 6.4 | Conversation Prefetch üÜï | `api.py` | Low | 2a.5 |

---

## –ß–∞—Å—Ç—å 5: –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

### –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–µ–µ | –¶–µ–ª–µ–≤–æ–µ | –ö–∞–∫ –∏–∑–º–µ—Ä—è—Ç—å |
|---------|---------|---------|--------------|
| Windows –∫–æ–º–∞–Ω–¥—ã —Ä–∞–±–æ—Ç–∞—é—Ç | 0% | 100% | `test_safe_shell.py` |
| –ó–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–∞ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã | 0% | 100% | verification_logs count |
| –õ–æ–∂–Ω—ã–µ "Task Done" | ~30% | <5% | verification.status == FAIL –ø–æ—Å–ª–µ COMPLETED |
| Routing accuracy | N/A | >85% | Manual eval –Ω–∞ 100 queries |
| PyBox sandbox –±–µ–∑–æ–ø–∞—Å–µ–Ω | N/A | 100% | Security test suite |
| Metrics –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è | –ß–∞—Å—Ç–∏—á–Ω–æ | 100% | interaction_outcomes per message |
| **ContextPrimer cache hit** ‚≠ê | N/A | >40% | `primed.from_cache == True` rate |
| **ContextPrimer prefetch time** ‚≠ê | N/A | <100ms | `primed.prime_time_ms` p95 |
| **Token reduction** ‚≠ê | N/A | >50% | (old_tokens - new_tokens) / old_tokens |

### –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ

- [ ] –ê–≥–µ–Ω—Ç –æ–±—ä—è—Å–Ω—è–µ—Ç –ü–û–ß–ï–ú–£ –æ–Ω —É–≤–µ—Ä–µ–Ω –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
- [ ] –ê–≥–µ–Ω—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—Ç, –∫–æ–≥–¥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è
- [ ] –ê–≥–µ–Ω—Ç –ø–æ–º–Ω–∏—Ç —Å–≤–æ–∏ –ø—Ä–æ—à–ª—ã–µ –æ—à–∏–±–∫–∏ (ErrorMemory)
- [ ] –ê–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏
- [ ] IQ/Empathy –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç—Ä–∞–∂–∞—é—Ç —Ä–µ–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ

---

## –ß–∞—Å—Ç—å 6: –†–∏—Å–∫–∏ –∏ –º–∏—Ç–∏–≥–∞—Ü–∏—è

| –†–∏—Å–∫ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | –í–ª–∏—è–Ω–∏–µ | –ú–∏—Ç–∏–≥–∞—Ü–∏—è |
|------|-------------|---------|-----------|
| Embedding API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω | Medium | High | Fallback –Ω–∞ keyword routing |
| –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–∞—è (LLM calls) | High | Medium | Confidence threshold –¥–ª—è skip |
| PyBox bypass | Low | Critical | Extensive security tests, AST whitelist |
| Breaking changes –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º API | Medium | High | –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, backward compat |
| Regression –≤ IQ/Empathy –º–µ—Ç—Ä–∏–∫–∞—Ö | Medium | Medium | Integration tests |
| ErrorMemory –¥—É–±–ª–∏—Ä—É–µ—Ç CorrectionDetector | Low | Low | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ, –Ω–µ –∑–∞–º–µ–Ω—É |

---

## –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ A: –ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ —Ñ–∞–π–ª–æ–≤

```text
src/core/
‚îú‚îÄ‚îÄ adaptation.py       # CorrectionDetector, FeedbackMiner [–°–£–©–ï–°–¢–í–£–ï–¢, + build_full_prompt]
‚îú‚îÄ‚îÄ autogpt.py          # AutoGPTAgent –±–∞–∑–æ–≤—ã–π [–°–£–©–ï–°–¢–í–£–ï–¢]
‚îú‚îÄ‚îÄ agent_v2.py         # NEW: ReflectiveAgent (—Ä–∞—Å—à–∏—Ä—è–µ—Ç autogpt)
‚îú‚îÄ‚îÄ config.py           # ThinkingModeConfig [–°–£–©–ï–°–¢–í–£–ï–¢]
‚îú‚îÄ‚îÄ confidence.py       # NEW: ConfidenceScorer
‚îú‚îÄ‚îÄ context_primer.py   # NEW: ContextPrimer (Semantic Prefetch) ‚≠ê
‚îú‚îÄ‚îÄ embedding_service.py # NEW: Shared EmbeddingService üÜï
‚îú‚îÄ‚îÄ error_memory.py     # NEW: ErrorMemory (—Ä–∞—Å—à–∏—Ä—è–µ—Ç CorrectionDetector)
‚îú‚îÄ‚îÄ lm_client.py        # LMStudioClient [–°–£–©–ï–°–¢–í–£–ï–¢, detect_task_type –ó–ê–ú–ï–ù–Ø–ï–¢–°–Ø]
‚îú‚îÄ‚îÄ memory.py           # MemoryManager [–°–£–©–ï–°–¢–í–£–ï–¢]
‚îú‚îÄ‚îÄ metrics.py          # MetricsEngine [–°–£–©–ï–°–¢–í–£–ï–¢]
‚îú‚îÄ‚îÄ pybox.py            # NEW: PyBox sandbox
‚îú‚îÄ‚îÄ safe_shell.py       # NEW: SafeShell (Windows)
‚îú‚îÄ‚îÄ self_reflection.py  # NEW: SelfReflection (—Å–∞–º–æ–∞–Ω–∞–ª–∏–∑ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è) ‚≠ê
‚îú‚îÄ‚îÄ semantic_router.py  # NEW: SemanticRouter
‚îú‚îÄ‚îÄ tools.py            # ToolManager [–°–£–©–ï–°–¢–í–£–ï–¢, + PyBox + SafeShell]
‚îî‚îÄ‚îÄ user_profile.py     # UserProfile [–°–£–©–ï–°–¢–í–£–ï–¢]

data/
‚îî‚îÄ‚îÄ schema.sql          # + error_memory, verification_logs [–î–û–ü–û–õ–ù–ò–¢–¨]

src/api/
‚îî‚îÄ‚îÄ api.py              # Integration point [–ò–ó–ú–ï–ù–ò–¢–¨]

tests/
‚îú‚îÄ‚îÄ test_safe_shell.py      # NEW
‚îú‚îÄ‚îÄ test_semantic_router.py # NEW
‚îú‚îÄ‚îÄ test_context_primer.py  # NEW ‚≠ê
‚îú‚îÄ‚îÄ test_embedding_service.py # NEW üÜï
‚îú‚îÄ‚îÄ test_agent_v2.py        # NEW
‚îú‚îÄ‚îÄ test_pybox.py           # NEW (CRITICAL SECURITY)
‚îú‚îÄ‚îÄ test_error_memory.py    # NEW
‚îî‚îÄ‚îÄ test_adaptation.py      # –°–£–©–ï–°–¢–í–£–ï–¢
```

---

## –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ B: Checklist –¥–ª—è Code Review

### SafeShell

- [ ] Windows built-ins wrapped correctly
- [ ] Linux commands work without wrapping
- [ ] Timeout kills process
- [ ] Output truncation works
- [ ] Real-time streaming callback works

### SemanticRouter

- [ ] Embeddings cached after init
- [ ] Fallback to keywords works when embedding fails
- [ ] UserProfile.verbosity respected
- [ ] Performance < 100ms per route
- [ ] All IntentCategories have examples

### ReflectiveAgent

- [ ] Extends AutoGPTAgent (–Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç)
- [ ] Verification prompt gives useful results
- [ ] Max retries respected (default 3)
- [ ] MetricsEngine.record_interaction_outcome called
- [ ] Doesn't break existing AutoGPT tests

### ErrorMemory

- [ ] Uses CorrectionDetector (–Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç)
- [ ] Vector similarity search works
- [ ] Warnings injected correctly
- [ ] Doesn't duplicate correction_log data
- [ ] Occurrences counter works

### PyBox

- [ ] ALL blocked imports rejected (os, sys, subprocess, etc.)
- [ ] ALL blocked calls rejected (exec, eval, open, etc.)
- [ ] Allowed imports work (math, json, datetime, etc.)
- [ ] Timeout kills process (10s)
- [ ] Output limit works (100KB)
- [ ] No file system access
- [ ] No network access
- [ ] **SECURITY TEST SUITE PASSES**

### ConfidenceScorer

- [ ] Hedging detection works (RU/EN)
- [ ] Score range valid (0-1)
- [ ] Level thresholds correct
- [ ] Integration with API done

### SelfReflection ‚≠ê

- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MetricsEngine (IQ/Empathy)
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CorrectionDetector (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏)
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å FeedbackMiner (—É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
- [ ] Streak calculation —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Fallback –¥–ª—è –ø–µ—Ä–≤—ã—Ö –¥–Ω–µ–π (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)
- [ ] –ú–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ
- [ ] –ù–µ –¥—É–±–ª–∏—Ä—É–µ—Ç AdaptivePromptBuilder
- [ ] Performance < 50ms
- [ ] –¢–µ—Å—Ç—ã –Ω–∞ edge cases (0 –¥–Ω–µ–π, 100 –¥–Ω–µ–π, –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥)

### Integration (api.py)

- [ ] semantic_router.initialize() at startup
- [ ] error_memory.initialize() at startup
- [ ] self_reflection.initialize() at startup ‚≠ê
- [ ] route used instead of request.thinking_mode
- [ ] self_reflection.build_reflection_prompt() –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º ‚≠ê
- [ ] confidence_scorer called after response
- [ ] metrics_engine.record_interaction_outcome called
- [ ] Backward compatibility maintained

---

**–î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏.**

*–í–µ—Ä—Å–∏—è 3.0 —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã MAX.*
*–í—Å–µ –Ω–æ–≤—ã–µ –º–æ–¥—É–ª–∏ –†–ê–°–®–ò–†–Ø–Æ–¢ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ, –Ω–µ –∑–∞–º–µ–Ω—è—é—Ç.*
